{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "91f2c03a-8120-48e8-bbff-cb837745ae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import PIL.ImageOps    \n",
    "import cv2\n",
    "import torchvision\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.utils\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as functional\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a857b79-836d-45b8-b7f2-82b3cea71c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SiameseNetworkDataset(Dataset):\n",
    "  def __init__(self,dataset,transformations=None):\n",
    "    self.dataset = dataset\n",
    "    self.transform =  transformations\n",
    "\n",
    "  def __getitem__(self,index):\n",
    "\n",
    "    randomImage = random.choice(self.dataset.imgs)\n",
    "    Image0 = Image.open(randomImage[0])\n",
    "    probability = random.randint(0,1)\n",
    "    \n",
    "    new_random_image = random.choice(self.dataset.imgs) \n",
    "  \n",
    "    if(probability):\n",
    "      while(new_random_image[1]!=randomImage[1]):\n",
    "        new_random_image = random.choice(self.dataset.imgs)\n",
    "        \n",
    "    else:\n",
    "      while(new_random_image[1]==randomImage[1]):\n",
    "        new_random_image = random.choice(self.dataset.imgs)\n",
    "\n",
    "   \n",
    "    Image0 = Image0.convert(\"L\")\n",
    "    Image1 = Image.open(new_random_image[0])\n",
    "    Image1 = Image1.convert(\"L\")\n",
    "\n",
    "    if(self.transform!=None):\n",
    "      Image0 = self.transform(Image0)\n",
    "      Image1 = self.transform(Image1)\n",
    "\n",
    "    return Image0,Image1,torch.from_numpy(np.array(int(randomImage[1]!=new_random_image[1]),dtype=np.float32))\n",
    "      \n",
    "  def __len__(self):\n",
    "        return len(self.dataset.imgs)\n",
    "        \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da6b5ac0-e365-46bc-8bcf-59b8042cb1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img, text=None):\n",
    "    npimg = img.numpy()\n",
    "    plt.axis(\"off\")\n",
    "    if text:\n",
    "        plt.text(75, 8, text, style='italic',fontweight='bold',\n",
    "            bbox={'facecolor':'white', 'alpha':0.8, 'pad':10})\n",
    "        \n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()    \n",
    "\n",
    "def show_plot(iteration,loss):\n",
    "    plt.plot(iteration,loss)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6ac338a-bbb7-4479-ab60-f4b12f3a89f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.Resize((100,100)),\n",
    "                  transforms.ToTensor()])\n",
    "folderDataset = datasets.ImageFolder(root = 'Train')\n",
    "Siamese_DataSet = SiameseNetworkDataset(dataset=folderDataset,transformations=transformations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a6ccff2-c919-44c3-b5b1-1e35c9cf4126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. 0. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "Visualize_Dataset = DataLoader(Siamese_DataSet,shuffle=True,batch_size=8)\n",
    "sample_batch = next(iter(Visualize_Dataset))\n",
    "Image_Concatenate = torch.cat((sample_batch[0],sample_batch[1]),0)\n",
    "imshow(torchvision.utils.make_grid(Image_Concatenate))\n",
    "print(sample_batch[2].numpy().reshape(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96adbbb4-3354-4a04-9695-b47bad752265",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Build_Siamese_Network(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(Build_Siamese_Network,self).__init__()\n",
    "    self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(1, 96, kernel_size=11,stride=4),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(3, stride=2),\n",
    "            \n",
    "            nn.Conv2d(96, 256, kernel_size=5, stride=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(2, stride=2),\n",
    "\n",
    "            nn.Conv2d(256, 384, kernel_size=3,stride=1),\n",
    "            nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "    self.connected = nn.Sequential(\n",
    "            nn.Linear(384, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(256,3)\n",
    "    )\n",
    "\n",
    "  def forward_once(self,input):\n",
    "      output = self.cnn(input)\n",
    "      output  = output.view(output.size()[0],-1)\n",
    "      output = self.connected(output)\n",
    "      return output\n",
    "\n",
    "  def forward(self, input1, input2):\n",
    "        output1 = self.forward_once(input1)\n",
    "        output2 = self.forward_once(input2)\n",
    "\n",
    "        return output1, output2\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f5894b8-26e6-4269-94f3-c34b696a620b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContrasiveLoss(nn.Module):\n",
    "  def __init__(self,margin=2.0):\n",
    "    super(ContrasiveLoss,self).__init__()\n",
    "    self.margin = margin\n",
    "  def forward(self,output1,output2,label):\n",
    "    output = functional.pairwise_distance(output1,output2)\n",
    "    loss =torch.mean((1-label)*(torch.pow(output,2)) + (label)*(torch.pow(torch.clamp(self.margin-output,min=0.0),2)))\n",
    "    return loss\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da4638cd-1f9e-4358-b487-a5ccde38bd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(Siamese_DataSet,shuffle=True,batch_size=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6c5bf90-9ea6-42a4-bf9e-ec94dcbdd537",
   "metadata": {},
   "outputs": [],
   "source": [
    "Siamese_model = Build_Siamese_Network()\n",
    "Contrasive_loss = ContrasiveLoss()\n",
    "optimizer = optim.Adam(Siamese_model.parameters(),lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2096c1d-abd3-4d99-897f-4073c2681bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.2275, 0.2196, 0.2078,  ..., 0.0039, 0.0039, 0.0000],\n",
      "          [0.3098, 0.2784, 0.2549,  ..., 0.0039, 0.0039, 0.0000],\n",
      "          [0.4196, 0.3843, 0.3490,  ..., 0.0039, 0.0039, 0.0000],\n",
      "          ...,\n",
      "          [0.3725, 0.2157, 0.1804,  ..., 0.0078, 0.0000, 0.0000],\n",
      "          [0.2431, 0.1882, 0.1765,  ..., 0.0078, 0.0000, 0.0000],\n",
      "          [0.1804, 0.1882, 0.1843,  ..., 0.0078, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0824, 0.0941, 0.1098,  ..., 0.1373, 0.1294, 0.1255],\n",
      "          [0.1529, 0.1020, 0.1020,  ..., 0.1373, 0.1294, 0.1294],\n",
      "          [0.2784, 0.1176, 0.0980,  ..., 0.1373, 0.1333, 0.1333]]],\n",
      "\n",
      "\n",
      "        [[[0.7608, 0.7686, 0.7804,  ..., 0.2980, 0.2941, 0.2902],\n",
      "          [0.7412, 0.7608, 0.7765,  ..., 0.3059, 0.3098, 0.3176],\n",
      "          [0.7098, 0.7412, 0.7686,  ..., 0.3373, 0.3490, 0.3647],\n",
      "          ...,\n",
      "          [0.0784, 0.0824, 0.0824,  ..., 0.1137, 0.1098, 0.1098],\n",
      "          [0.0706, 0.0745, 0.0824,  ..., 0.0980, 0.1059, 0.1137],\n",
      "          [0.0745, 0.0745, 0.0824,  ..., 0.0941, 0.0980, 0.1059]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.0784, 0.0902, 0.1255,  ..., 0.2706, 0.2549, 0.2510],\n",
      "          [0.0745, 0.0824, 0.0941,  ..., 0.2549, 0.2392, 0.2392],\n",
      "          [0.0784, 0.0784, 0.0902,  ..., 0.2431, 0.2353, 0.2353]]],\n",
      "\n",
      "\n",
      "        [[[0.3255, 0.2941, 0.2745,  ..., 0.8196, 0.8157, 0.8118],\n",
      "          [0.4353, 0.3961, 0.3608,  ..., 0.8275, 0.8196, 0.8196],\n",
      "          [0.5647, 0.5294, 0.4941,  ..., 0.8235, 0.8196, 0.8196],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4627, 0.4706, 0.4784,  ..., 0.0706, 0.1059, 0.1373],\n",
      "          [0.5020, 0.4902, 0.4980,  ..., 0.0275, 0.0549, 0.0824],\n",
      "          [0.5804, 0.5608, 0.5725,  ..., 0.0078, 0.0196, 0.0392],\n",
      "          ...,\n",
      "          [0.6627, 0.6275, 0.5843,  ..., 0.2275, 0.2275, 0.2314],\n",
      "          [0.6706, 0.6431, 0.6039,  ..., 0.1882, 0.1804, 0.1922],\n",
      "          [0.6745, 0.6510, 0.6118,  ..., 0.1569, 0.1451, 0.1569]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.1873, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.187280297279358\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1451, 0.1451, 0.1529,  ..., 0.1451, 0.1137, 0.1176],\n",
      "          [0.1451, 0.1451, 0.1529,  ..., 0.1529, 0.1216, 0.1137],\n",
      "          [0.1451, 0.1451, 0.1529,  ..., 0.1569, 0.1255, 0.1137]]],\n",
      "\n",
      "\n",
      "        [[[0.0745, 0.0863, 0.0784,  ..., 0.0980, 0.0941, 0.0902],\n",
      "          [0.0745, 0.0824, 0.0745,  ..., 0.1020, 0.0863, 0.0863],\n",
      "          [0.0706, 0.0706, 0.0627,  ..., 0.0941, 0.0863, 0.0902],\n",
      "          ...,\n",
      "          [0.0353, 0.0353, 0.0392,  ..., 0.0941, 0.1020, 0.1098],\n",
      "          [0.0431, 0.0392, 0.0392,  ..., 0.1020, 0.1059, 0.1098],\n",
      "          [0.0431, 0.0392, 0.0431,  ..., 0.1059, 0.1059, 0.1098]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.3490, 0.3255, 0.2392,  ..., 0.4314, 0.3843, 0.1725],\n",
      "          [0.3686, 0.3451, 0.2667,  ..., 0.4275, 0.3725, 0.1765],\n",
      "          [0.3804, 0.3608, 0.3216,  ..., 0.4157, 0.3569, 0.1725]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0039,  ..., 0.4824, 0.6078, 0.7294],\n",
      "          [0.0000, 0.0000, 0.0039,  ..., 0.3843, 0.4902, 0.6431],\n",
      "          [0.0000, 0.0000, 0.0039,  ..., 0.3333, 0.4078, 0.5176],\n",
      "          ...,\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.7725, 0.7725, 0.8157],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.7686, 0.7843, 0.8157],\n",
      "          [0.0000, 0.0000, 0.0039,  ..., 0.7686, 0.7882, 0.8196]]],\n",
      "\n",
      "\n",
      "        [[[0.2471, 0.2784, 0.3020,  ..., 0.2549, 0.3098, 0.3216],\n",
      "          [0.2471, 0.2784, 0.3059,  ..., 0.2549, 0.3098, 0.3216],\n",
      "          [0.2471, 0.2824, 0.3059,  ..., 0.2549, 0.3098, 0.3216],\n",
      "          ...,\n",
      "          [0.1137, 0.0902, 0.1059,  ..., 0.1412, 0.1098, 0.0980],\n",
      "          [0.0824, 0.0745, 0.1059,  ..., 0.1333, 0.1176, 0.0941],\n",
      "          [0.0510, 0.0745, 0.1059,  ..., 0.1294, 0.1176, 0.0902]]],\n",
      "\n",
      "\n",
      "        [[[0.7608, 0.7490, 0.7137,  ..., 0.4471, 0.4471, 0.4235],\n",
      "          [0.7608, 0.7451, 0.7098,  ..., 0.5725, 0.5882, 0.5843],\n",
      "          [0.7608, 0.7412, 0.7059,  ..., 0.6314, 0.6627, 0.6706],\n",
      "          ...,\n",
      "          [0.2941, 0.3294, 0.3294,  ..., 0.2824, 0.2745, 0.2863],\n",
      "          [0.2275, 0.2588, 0.3020,  ..., 0.2745, 0.2784, 0.2824],\n",
      "          [0.2902, 0.2431, 0.2275,  ..., 0.2667, 0.2667, 0.2706]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.4574, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.4573792219161987\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.2667, 0.2863, 0.2510,  ..., 0.1529, 0.1490, 0.1412],\n",
      "          [0.2667, 0.3137, 0.2745,  ..., 0.1569, 0.1412, 0.1373],\n",
      "          [0.2392, 0.2824, 0.2627,  ..., 0.1412, 0.1294, 0.1333]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.2039, 0.2078, 0.2078,  ..., 0.1922, 0.1843, 0.2824],\n",
      "          [0.2039, 0.2039, 0.2039,  ..., 0.1922, 0.1804, 0.2392],\n",
      "          [0.2039, 0.2039, 0.2000,  ..., 0.1961, 0.1882, 0.2353]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0902, 0.1294, 0.1255,  ..., 0.0784, 0.0824, 0.0627],\n",
      "          [0.0745, 0.1137, 0.0863,  ..., 0.0784, 0.0588, 0.0588],\n",
      "          [0.0706, 0.0902, 0.0510,  ..., 0.0588, 0.0706, 0.0745]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0039, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.2157, 0.2118, 0.2039,  ..., 0.1412, 0.1412, 0.1412],\n",
      "          [0.6627, 0.6510, 0.6314,  ..., 0.4353, 0.4392, 0.4353],\n",
      "          ...,\n",
      "          [0.1255, 0.1333, 0.1333,  ..., 0.1098, 0.1176, 0.1176],\n",
      "          [0.1176, 0.1255, 0.1294,  ..., 0.1020, 0.1137, 0.1216],\n",
      "          [0.1137, 0.1216, 0.1255,  ..., 0.1059, 0.1137, 0.1255]]],\n",
      "\n",
      "\n",
      "        [[[0.3098, 0.2980, 0.2824,  ..., 0.3373, 0.3451, 0.3490],\n",
      "          [0.3059, 0.2902, 0.2588,  ..., 0.4275, 0.4314, 0.4353],\n",
      "          [0.3020, 0.2745, 0.2235,  ..., 0.4745, 0.4745, 0.4745],\n",
      "          ...,\n",
      "          [0.0392, 0.0314, 0.0314,  ..., 0.0157, 0.0118, 0.0118],\n",
      "          [0.0392, 0.0392, 0.0314,  ..., 0.0235, 0.0118, 0.0078],\n",
      "          [0.0392, 0.0353, 0.0314,  ..., 0.0275, 0.0196, 0.0157]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1961, 0.1804, 0.1686,  ..., 0.0863, 0.0941, 0.1373],\n",
      "          [0.1922, 0.1843, 0.1647,  ..., 0.0863, 0.0863, 0.0824],\n",
      "          [0.1922, 0.1882, 0.1608,  ..., 0.0941, 0.0941, 0.1059]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.3904, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.3903566598892212\n",
      "\n",
      "tensor([[[[0.3961, 0.3961, 0.3961,  ..., 0.3961, 0.3961, 0.3961],\n",
      "          [0.7373, 0.7373, 0.7373,  ..., 0.7294, 0.7294, 0.7294],\n",
      "          [0.7451, 0.7451, 0.7451,  ..., 0.7412, 0.7412, 0.7412],\n",
      "          ...,\n",
      "          [0.4980, 0.4941, 0.6549,  ..., 0.5216, 0.5804, 0.5804],\n",
      "          [0.5451, 0.5569, 0.6863,  ..., 0.5569, 0.5725, 0.5569],\n",
      "          [0.5725, 0.6510, 0.7804,  ..., 0.5686, 0.5490, 0.5569]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1882, 0.1961, 0.1961,  ..., 0.2353, 0.2275, 0.2235],\n",
      "          [0.1765, 0.1843, 0.1882,  ..., 0.2314, 0.2235, 0.2196],\n",
      "          [0.1647, 0.1725, 0.1843,  ..., 0.2275, 0.2196, 0.2157]]],\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0039, 0.0039,  ..., 0.2235, 0.2353, 0.2353],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.2353, 0.2314, 0.2235],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.3412, 0.3176, 0.2941],\n",
      "          ...,\n",
      "          [0.1412, 0.1569, 0.1686,  ..., 0.3176, 0.2314, 0.1686],\n",
      "          [0.1451, 0.1569, 0.1725,  ..., 0.3020, 0.2157, 0.1647],\n",
      "          [0.1255, 0.1412, 0.1569,  ..., 0.2745, 0.2000, 0.1647]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.1020, 0.1020, 0.1020,  ..., 0.0706, 0.0706, 0.0627],\n",
      "          [0.6824, 0.6784, 0.6706,  ..., 0.4392, 0.4235, 0.3922],\n",
      "          [0.7647, 0.7569, 0.7529,  ..., 0.5569, 0.5373, 0.5020],\n",
      "          ...,\n",
      "          [0.1529, 0.1569, 0.1569,  ..., 0.1373, 0.1294, 0.1333],\n",
      "          [0.1569, 0.1451, 0.1333,  ..., 0.1333, 0.1255, 0.1216],\n",
      "          [0.1529, 0.1412, 0.1176,  ..., 0.1294, 0.1216, 0.1059]]],\n",
      "\n",
      "\n",
      "        [[[0.8471, 0.8627, 0.8706,  ..., 0.4706, 0.4706, 0.4627],\n",
      "          [0.8157, 0.8314, 0.8471,  ..., 0.5059, 0.5216, 0.5294],\n",
      "          [0.7725, 0.7882, 0.8000,  ..., 0.5647, 0.6000, 0.6196],\n",
      "          ...,\n",
      "          [0.5176, 0.5176, 0.5176,  ..., 0.0549, 0.1176, 0.1333],\n",
      "          [0.5137, 0.5137, 0.5137,  ..., 0.1137, 0.1922, 0.1961],\n",
      "          [0.5255, 0.5255, 0.5255,  ..., 0.1765, 0.2196, 0.2275]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0745, 0.0941, 0.0980,  ..., 0.1020, 0.0980, 0.0980],\n",
      "          [0.0784, 0.0980, 0.1020,  ..., 0.1020, 0.0980, 0.0941],\n",
      "          [0.0824, 0.0941, 0.0980,  ..., 0.0980, 0.0941, 0.0902]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.3662, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.366241455078125\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0314, 0.0392, 0.0431,  ..., 0.0314, 0.0275, 0.0353],\n",
      "          [0.0314, 0.0431, 0.0471,  ..., 0.0353, 0.0275, 0.0314],\n",
      "          [0.0314, 0.0353, 0.0431,  ..., 0.0314, 0.0275, 0.0275]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1333, 0.1294, 0.1216,  ..., 0.1176, 0.1255, 0.1216],\n",
      "          [0.1255, 0.1255, 0.1216,  ..., 0.1176, 0.1176, 0.1059],\n",
      "          [0.1216, 0.1216, 0.1255,  ..., 0.1176, 0.1176, 0.1059]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0039, 0.0000],\n",
      "          [0.1804, 0.1804, 0.1804,  ..., 0.2471, 0.2471, 0.2431],\n",
      "          [0.6353, 0.6353, 0.6275,  ..., 0.8667, 0.8588, 0.8588],\n",
      "          ...,\n",
      "          [0.5216, 0.5216, 0.5216,  ..., 0.1490, 0.1490, 0.1294],\n",
      "          [0.5216, 0.5216, 0.5216,  ..., 0.1569, 0.1412, 0.1216],\n",
      "          [0.5255, 0.5255, 0.5216,  ..., 0.1529, 0.1412, 0.1294]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0549, 0.1020, 0.1294],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0588, 0.0588, 0.0745],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0549, 0.0588, 0.0588]]],\n",
      "\n",
      "\n",
      "        [[[0.6824, 0.6902, 0.6941,  ..., 0.4118, 0.4157, 0.4196],\n",
      "          [0.6941, 0.6980, 0.6941,  ..., 0.4980, 0.5216, 0.5412],\n",
      "          [0.7098, 0.7098, 0.7059,  ..., 0.6863, 0.7255, 0.7529],\n",
      "          ...,\n",
      "          [0.9843, 0.9804, 0.9804,  ..., 0.1333, 0.1686, 0.1922],\n",
      "          [0.9843, 0.9804, 0.9725,  ..., 0.2980, 0.3451, 0.3725],\n",
      "          [0.9804, 0.9725, 0.9647,  ..., 0.3882, 0.4275, 0.4510]]],\n",
      "\n",
      "\n",
      "        [[[0.7608, 0.7490, 0.7137,  ..., 0.4471, 0.4471, 0.4235],\n",
      "          [0.7608, 0.7451, 0.7098,  ..., 0.5725, 0.5882, 0.5843],\n",
      "          [0.7608, 0.7412, 0.7059,  ..., 0.6314, 0.6627, 0.6706],\n",
      "          ...,\n",
      "          [0.2941, 0.3294, 0.3294,  ..., 0.2824, 0.2745, 0.2863],\n",
      "          [0.2275, 0.2588, 0.3020,  ..., 0.2745, 0.2784, 0.2824],\n",
      "          [0.2902, 0.2431, 0.2275,  ..., 0.2667, 0.2667, 0.2706]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.5410, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.5409590005874634\n",
      "\n",
      "tensor([[[[0.0157, 0.0078, 0.0118,  ..., 0.8118, 0.8118, 0.8118],\n",
      "          [0.0118, 0.0039, 0.0039,  ..., 0.8118, 0.8118, 0.8118],\n",
      "          [0.0118, 0.0078, 0.0039,  ..., 0.8118, 0.8118, 0.8118],\n",
      "          ...,\n",
      "          [0.0314, 0.0353, 0.0392,  ..., 0.1608, 0.2980, 0.4235],\n",
      "          [0.0235, 0.0392, 0.0471,  ..., 0.2196, 0.4078, 0.5137],\n",
      "          [0.0196, 0.0314, 0.0392,  ..., 0.3137, 0.4745, 0.5098]]],\n",
      "\n",
      "\n",
      "        [[[0.4510, 0.4510, 0.4471,  ..., 0.7176, 0.7137, 0.7176],\n",
      "          [0.4784, 0.4784, 0.4706,  ..., 0.7137, 0.7098, 0.7176],\n",
      "          [0.5059, 0.5059, 0.5020,  ..., 0.7098, 0.7059, 0.7098],\n",
      "          ...,\n",
      "          [0.1059, 0.1216, 0.1373,  ..., 0.3843, 0.3843, 0.3843],\n",
      "          [0.1020, 0.1255, 0.1412,  ..., 0.3098, 0.3059, 0.2824],\n",
      "          [0.1137, 0.1412, 0.1451,  ..., 0.2627, 0.2627, 0.2353]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1922, 0.1765, 0.1725,  ..., 0.1098, 0.1176, 0.1255],\n",
      "          [0.1843, 0.1804, 0.1686,  ..., 0.1176, 0.1255, 0.1294],\n",
      "          [0.1922, 0.1804, 0.1686,  ..., 0.1255, 0.1294, 0.1333]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.3020, 0.2980, 0.2824,  ..., 0.2745, 0.2745, 0.2667],\n",
      "          [0.3020, 0.2980, 0.2824,  ..., 0.2745, 0.2745, 0.2667],\n",
      "          [0.3020, 0.2980, 0.2824,  ..., 0.2745, 0.2745, 0.2667],\n",
      "          ...,\n",
      "          [0.0431, 0.0353, 0.0431,  ..., 0.1333, 0.1412, 0.1373],\n",
      "          [0.0392, 0.0196, 0.0235,  ..., 0.1333, 0.1333, 0.1333],\n",
      "          [0.0235, 0.0275, 0.0275,  ..., 0.1294, 0.1333, 0.1333]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1176, 0.1137, 0.1020,  ..., 0.0745, 0.0745, 0.0745],\n",
      "          [0.1098, 0.1059, 0.0980,  ..., 0.0745, 0.0745, 0.0745],\n",
      "          [0.1020, 0.1020, 0.0941,  ..., 0.0745, 0.0745, 0.0745]]],\n",
      "\n",
      "\n",
      "        [[[0.4392, 0.5137, 0.6000,  ..., 0.3569, 0.5922, 0.7529],\n",
      "          [0.4275, 0.4784, 0.5569,  ..., 0.3412, 0.5882, 0.7490],\n",
      "          [0.3961, 0.4353, 0.5059,  ..., 0.2980, 0.5804, 0.7686],\n",
      "          ...,\n",
      "          [0.2039, 0.2039, 0.2392,  ..., 0.3333, 0.2784, 0.0745],\n",
      "          [0.1961, 0.2078, 0.2510,  ..., 0.3255, 0.2745, 0.0941],\n",
      "          [0.1961, 0.2039, 0.2510,  ..., 0.3255, 0.2706, 0.1137]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.7728, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.7727689743041992\n",
      "\n",
      "tensor([[[[0.4196, 0.4235, 0.4196,  ..., 0.3765, 0.3765, 0.3765],\n",
      "          [0.4039, 0.4039, 0.4118,  ..., 0.3686, 0.3686, 0.3725],\n",
      "          [0.3686, 0.3725, 0.3765,  ..., 0.3725, 0.3725, 0.3765],\n",
      "          ...,\n",
      "          [0.0902, 0.0902, 0.0902,  ..., 0.0863, 0.0863, 0.0863],\n",
      "          [0.0902, 0.0902, 0.0902,  ..., 0.0941, 0.0941, 0.0941],\n",
      "          [0.0902, 0.0902, 0.0863,  ..., 0.1020, 0.1020, 0.0980]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1373, 0.1333, 0.1333,  ..., 0.1059, 0.0824, 0.0667],\n",
      "          [0.1608, 0.1608, 0.1569,  ..., 0.0980, 0.0745, 0.0745],\n",
      "          [0.1765, 0.1804, 0.1765,  ..., 0.0941, 0.0667, 0.0627]]],\n",
      "\n",
      "\n",
      "        [[[0.4471, 0.4510, 0.4588,  ..., 0.4902, 0.5020, 0.5098],\n",
      "          [0.4471, 0.4510, 0.4588,  ..., 0.5373, 0.5412, 0.5412],\n",
      "          [0.4392, 0.4431, 0.4431,  ..., 0.5647, 0.5569, 0.5451],\n",
      "          ...,\n",
      "          [0.8235, 0.8275, 0.8392,  ..., 0.7059, 0.6588, 0.6275],\n",
      "          [0.8078, 0.8157, 0.8275,  ..., 0.6902, 0.6784, 0.6471],\n",
      "          [0.8078, 0.8196, 0.8314,  ..., 0.5647, 0.6745, 0.6510]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0275, 0.0039, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0588, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.0039, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0039],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.1020, 0.0941, 0.1098,  ..., 0.2000, 0.2000, 0.1804],\n",
      "          [0.0941, 0.0941, 0.1020,  ..., 0.1882, 0.1765, 0.1490],\n",
      "          [0.0863, 0.0902, 0.0980,  ..., 0.1725, 0.1529, 0.1216]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0314, 0.0706, 0.1333,  ..., 0.6157, 0.6157, 0.6196],\n",
      "          [0.0353, 0.0549, 0.1216,  ..., 0.6157, 0.6157, 0.6196],\n",
      "          [0.0510, 0.0431, 0.1020,  ..., 0.6157, 0.6196, 0.6196]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.0585, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.0584938526153564\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0902, 0.0902, 0.0784,  ..., 0.4000, 0.4275, 0.4588],\n",
      "          [0.0784, 0.0863, 0.0863,  ..., 0.4078, 0.4353, 0.4000],\n",
      "          [0.0824, 0.0863, 0.0941,  ..., 0.4000, 0.4078, 0.3647]]],\n",
      "\n",
      "\n",
      "        [[[0.8157, 0.8196, 0.8196,  ..., 0.0588, 0.0627, 0.0667],\n",
      "          [0.8196, 0.8196, 0.8196,  ..., 0.1176, 0.1020, 0.1020],\n",
      "          [0.8235, 0.8235, 0.8235,  ..., 0.3137, 0.2706, 0.2588],\n",
      "          ...,\n",
      "          [0.3961, 0.4000, 0.3765,  ..., 0.3686, 0.4510, 0.3843],\n",
      "          [0.3529, 0.3922, 0.3961,  ..., 0.3608, 0.4431, 0.3333],\n",
      "          [0.2980, 0.3412, 0.3843,  ..., 0.3608, 0.4353, 0.2980]]],\n",
      "\n",
      "\n",
      "        [[[0.0353, 0.1451, 0.1647,  ..., 0.2588, 0.2824, 0.3020],\n",
      "          [0.0353, 0.1451, 0.1647,  ..., 0.2588, 0.2824, 0.3020],\n",
      "          [0.0353, 0.1451, 0.1647,  ..., 0.2627, 0.2824, 0.3020],\n",
      "          ...,\n",
      "          [0.0039, 0.0196, 0.0275,  ..., 0.0667, 0.0627, 0.0588],\n",
      "          [0.0039, 0.0196, 0.0196,  ..., 0.0549, 0.0588, 0.0588],\n",
      "          [0.0039, 0.0118, 0.0157,  ..., 0.0471, 0.0549, 0.0549]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1373, 0.1333, 0.1255],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1490, 0.1490, 0.1333],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1569, 0.1608, 0.1412]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0039, 0.0000],\n",
      "          [0.1804, 0.1804, 0.1804,  ..., 0.2471, 0.2471, 0.2431],\n",
      "          [0.6353, 0.6353, 0.6275,  ..., 0.8667, 0.8588, 0.8588],\n",
      "          ...,\n",
      "          [0.5216, 0.5216, 0.5216,  ..., 0.1490, 0.1490, 0.1294],\n",
      "          [0.5216, 0.5216, 0.5216,  ..., 0.1569, 0.1412, 0.1216],\n",
      "          [0.5255, 0.5255, 0.5216,  ..., 0.1529, 0.1412, 0.1294]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0667, 0.0627, 0.0627,  ..., 0.0706, 0.0706, 0.0706],\n",
      "          [0.0627, 0.0588, 0.0588,  ..., 0.0706, 0.0706, 0.0667],\n",
      "          [0.0667, 0.0627, 0.0588,  ..., 0.0706, 0.0706, 0.0667]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(0.9978, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 0.9978362917900085\n",
      "\n",
      "tensor([[[[0.6706, 0.6863, 0.6471,  ..., 0.1412, 0.1333, 0.1333],\n",
      "          [0.6314, 0.6431, 0.5961,  ..., 0.1373, 0.1373, 0.1412],\n",
      "          [0.5686, 0.6196, 0.5882,  ..., 0.1333, 0.1412, 0.1451],\n",
      "          ...,\n",
      "          [0.3608, 0.1725, 0.1176,  ..., 0.1647, 0.1569, 0.1608],\n",
      "          [0.4588, 0.2510, 0.1451,  ..., 0.1608, 0.1608, 0.1647],\n",
      "          [0.5529, 0.3647, 0.2196,  ..., 0.1647, 0.1608, 0.1608]]],\n",
      "\n",
      "\n",
      "        [[[0.6627, 0.6667, 0.6706,  ..., 0.6863, 0.6863, 0.6863],\n",
      "          [0.6667, 0.6667, 0.6667,  ..., 0.6863, 0.6863, 0.6863],\n",
      "          [0.6667, 0.6667, 0.6667,  ..., 0.6824, 0.6824, 0.6824],\n",
      "          ...,\n",
      "          [0.1490, 0.1647, 0.1725,  ..., 0.2078, 0.2157, 0.2235],\n",
      "          [0.1451, 0.1647, 0.1765,  ..., 0.2039, 0.2118, 0.2196],\n",
      "          [0.1608, 0.1608, 0.1765,  ..., 0.2078, 0.2157, 0.2235]]],\n",
      "\n",
      "\n",
      "        [[[0.3608, 0.3882, 0.4353,  ..., 0.3137, 0.3098, 0.3059],\n",
      "          [0.3608, 0.3765, 0.4235,  ..., 0.3137, 0.3098, 0.3059],\n",
      "          [0.3569, 0.3569, 0.4078,  ..., 0.3137, 0.3098, 0.3059],\n",
      "          ...,\n",
      "          [0.1843, 0.1843, 0.2000,  ..., 0.1451, 0.0941, 0.0902],\n",
      "          [0.1804, 0.1961, 0.1961,  ..., 0.1255, 0.0863, 0.0980],\n",
      "          [0.1843, 0.1882, 0.1922,  ..., 0.1059, 0.0902, 0.1020]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.2745, 0.2784, 0.2784,  ..., 0.3725, 0.3765, 0.3765],\n",
      "          [0.2745, 0.2824, 0.2784,  ..., 0.3725, 0.3765, 0.3725],\n",
      "          [0.2824, 0.2863, 0.2824,  ..., 0.3765, 0.3725, 0.3765],\n",
      "          ...,\n",
      "          [0.0510, 0.0549, 0.0627,  ..., 0.5608, 0.6627, 0.6784],\n",
      "          [0.0510, 0.0510, 0.0588,  ..., 0.5020, 0.6431, 0.7529],\n",
      "          [0.0627, 0.0588, 0.0627,  ..., 0.4941, 0.6745, 0.7882]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0980, 0.0980, 0.0863],\n",
      "          [0.0314, 0.0314, 0.0353,  ..., 0.0980, 0.0941, 0.0863],\n",
      "          [0.0314, 0.0353, 0.0314,  ..., 0.1059, 0.0941, 0.0863]]],\n",
      "\n",
      "\n",
      "        [[[0.4902, 0.5176, 0.4902,  ..., 0.4353, 0.4941, 0.5176],\n",
      "          [0.4902, 0.4902, 0.4471,  ..., 0.4118, 0.4471, 0.4471],\n",
      "          [0.5059, 0.4941, 0.4588,  ..., 0.4392, 0.4627, 0.4549],\n",
      "          ...,\n",
      "          [0.0392, 0.0275, 0.0471,  ..., 0.2235, 0.2275, 0.2118],\n",
      "          [0.0314, 0.0471, 0.1961,  ..., 0.2039, 0.2039, 0.2078],\n",
      "          [0.0275, 0.0235, 0.1059,  ..., 0.1686, 0.1686, 0.1765]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.2873, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.2873393297195435\n",
      "\n",
      "tensor([[[[0.0745, 0.0745, 0.0706,  ..., 0.5608, 0.6824, 0.6706],\n",
      "          [0.0667, 0.0745, 0.0745,  ..., 0.5412, 0.6588, 0.6549],\n",
      "          [0.0588, 0.0667, 0.0784,  ..., 0.5294, 0.6353, 0.6392],\n",
      "          ...,\n",
      "          [0.0588, 0.0588, 0.0706,  ..., 0.0431, 0.0471, 0.0510],\n",
      "          [0.0392, 0.0510, 0.0667,  ..., 0.0353, 0.0431, 0.0471],\n",
      "          [0.0392, 0.0510, 0.0588,  ..., 0.0353, 0.0431, 0.0431]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.3098, 0.3137, 0.3176],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.3255, 0.3294, 0.3333],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.3451, 0.3490, 0.3529],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.6078, 0.4902, 0.1843],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.6157, 0.5647, 0.2588],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.6118, 0.5843, 0.2980]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1804, 0.0784, 0.0431,  ..., 0.0471, 0.0392, 0.0392],\n",
      "          [0.0588, 0.0392, 0.0471,  ..., 0.0510, 0.0510, 0.0471],\n",
      "          [0.0471, 0.0471, 0.0510,  ..., 0.0549, 0.0627, 0.0549]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.3569, 0.3412, 0.3608,  ..., 0.3216, 0.2863, 0.2353],\n",
      "          [0.3294, 0.3176, 0.3294,  ..., 0.2902, 0.2627, 0.2157],\n",
      "          [0.3098, 0.2902, 0.2980,  ..., 0.2902, 0.2745, 0.2392],\n",
      "          ...,\n",
      "          [0.3412, 0.3059, 0.1882,  ..., 0.0196, 0.0275, 0.0235],\n",
      "          [0.2745, 0.1725, 0.0941,  ..., 0.0196, 0.0275, 0.0275],\n",
      "          [0.1882, 0.0824, 0.0588,  ..., 0.0196, 0.0196, 0.0235]]],\n",
      "\n",
      "\n",
      "        [[[0.4196, 0.4039, 0.3765,  ..., 0.2000, 0.2314, 0.2863],\n",
      "          [0.4196, 0.4039, 0.3765,  ..., 0.2000, 0.2353, 0.2863],\n",
      "          [0.4196, 0.4039, 0.3765,  ..., 0.1961, 0.2392, 0.2941],\n",
      "          ...,\n",
      "          [0.8431, 0.8235, 0.7608,  ..., 0.5333, 0.4745, 0.4314],\n",
      "          [0.7843, 0.8431, 0.8431,  ..., 0.4157, 0.3569, 0.2902],\n",
      "          [0.7098, 0.7882, 0.8471,  ..., 0.2784, 0.2118, 0.2039]]],\n",
      "\n",
      "\n",
      "        [[[0.1176, 0.1412, 0.1922,  ..., 0.3569, 0.3412, 0.3294],\n",
      "          [0.1098, 0.1412, 0.1922,  ..., 0.3569, 0.3412, 0.3255],\n",
      "          [0.1059, 0.1373, 0.1882,  ..., 0.3569, 0.3373, 0.3137],\n",
      "          ...,\n",
      "          [0.1882, 0.1804, 0.1922,  ..., 0.2235, 0.2039, 0.1843],\n",
      "          [0.1608, 0.1294, 0.1451,  ..., 0.2196, 0.2000, 0.1569],\n",
      "          [0.1843, 0.1098, 0.0980,  ..., 0.2157, 0.1882, 0.1059]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.1016, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.1016451120376587\n",
      "\n",
      "tensor([[[[0.3882, 0.3804, 0.3882,  ..., 0.5608, 0.4667, 0.3961],\n",
      "          [0.3922, 0.3882, 0.3922,  ..., 0.5373, 0.4941, 0.4078],\n",
      "          [0.3922, 0.3922, 0.3922,  ..., 0.5255, 0.5098, 0.4314],\n",
      "          ...,\n",
      "          [0.0314, 0.0314, 0.0353,  ..., 0.0627, 0.0627, 0.0588],\n",
      "          [0.0235, 0.0275, 0.0314,  ..., 0.0588, 0.0627, 0.0667],\n",
      "          [0.0235, 0.0275, 0.0314,  ..., 0.0627, 0.0667, 0.0627]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.2510, 0.2471, 0.2431,  ..., 0.0196, 0.0039, 0.0039],\n",
      "          [0.2392, 0.2353, 0.2431,  ..., 0.0196, 0.0039, 0.0039],\n",
      "          [0.2275, 0.2275, 0.2353,  ..., 0.0196, 0.0039, 0.0039]]],\n",
      "\n",
      "\n",
      "        [[[0.7843, 0.7922, 0.7961,  ..., 0.5255, 0.5216, 0.5216],\n",
      "          [0.7843, 0.7922, 0.7961,  ..., 0.5059, 0.5176, 0.5255],\n",
      "          [0.7843, 0.7922, 0.7961,  ..., 0.4980, 0.5059, 0.5176],\n",
      "          ...,\n",
      "          [0.0980, 0.0706, 0.1569,  ..., 0.0941, 0.0863, 0.0824],\n",
      "          [0.0941, 0.0667, 0.1490,  ..., 0.0902, 0.0784, 0.0824],\n",
      "          [0.0980, 0.0667, 0.1412,  ..., 0.0941, 0.0784, 0.0784]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0118, 0.0078, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0118, 0.0078, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0078,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0000, 0.0196,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1647, 0.1647, 0.1608,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.1647, 0.1686, 0.1686,  ..., 0.0039, 0.0000, 0.0000],\n",
      "          [0.1647, 0.1647, 0.1686,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.5451, 0.5490, 0.5451,  ..., 0.1255, 0.1333, 0.1255],\n",
      "          [0.5451, 0.5490, 0.5176,  ..., 0.1255, 0.1333, 0.1373],\n",
      "          [0.5451, 0.5490, 0.4627,  ..., 0.1333, 0.1255, 0.1216]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.5247, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.5246515274047852\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.2039, 0.3490, 0.5373,  ..., 0.1255, 0.1294, 0.1294],\n",
      "          [0.2157, 0.3529, 0.5333,  ..., 0.1216, 0.1216, 0.1255],\n",
      "          [0.2196, 0.3608, 0.5255,  ..., 0.1216, 0.1216, 0.1255]]],\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0039, 0.0000,  ..., 0.0000, 0.0039, 0.0000],\n",
      "          [0.0118, 0.0118, 0.0118,  ..., 0.0196, 0.0196, 0.0196],\n",
      "          [0.2118, 0.2157, 0.2118,  ..., 0.3961, 0.3922, 0.3843],\n",
      "          ...,\n",
      "          [0.1373, 0.1373, 0.1373,  ..., 0.1137, 0.1176, 0.1137],\n",
      "          [0.1255, 0.1294, 0.1255,  ..., 0.1098, 0.1176, 0.1137],\n",
      "          [0.1059, 0.1137, 0.1176,  ..., 0.1137, 0.1176, 0.1176]]],\n",
      "\n",
      "\n",
      "        [[[0.1412, 0.1373, 0.1373,  ..., 0.2941, 0.5137, 0.6510],\n",
      "          [0.1451, 0.1373, 0.1373,  ..., 0.2431, 0.4392, 0.6196],\n",
      "          [0.1451, 0.1373, 0.1373,  ..., 0.2000, 0.3569, 0.5529],\n",
      "          ...,\n",
      "          [0.2314, 0.2471, 0.2549,  ..., 0.0549, 0.0706, 0.0745],\n",
      "          [0.2078, 0.2196, 0.2196,  ..., 0.0667, 0.0667, 0.0627],\n",
      "          [0.1922, 0.2000, 0.1961,  ..., 0.0706, 0.0667, 0.0549]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0314, 0.0314, 0.0314,  ..., 0.0353, 0.0314, 0.0314],\n",
      "          [0.2941, 0.2941, 0.2941,  ..., 0.2980, 0.2863, 0.2824],\n",
      "          [0.3882, 0.3882, 0.3882,  ..., 0.3961, 0.3843, 0.3843],\n",
      "          ...,\n",
      "          [0.7098, 0.7176, 0.7098,  ..., 0.2392, 0.2118, 0.1843],\n",
      "          [0.7059, 0.7059, 0.6941,  ..., 0.2392, 0.2039, 0.1765],\n",
      "          [0.6980, 0.6902, 0.6863,  ..., 0.2353, 0.1961, 0.1725]]],\n",
      "\n",
      "\n",
      "        [[[0.7176, 0.7137, 0.6863,  ..., 0.3765, 0.3765, 0.3804],\n",
      "          [0.6549, 0.6745, 0.6902,  ..., 0.3686, 0.3765, 0.3804],\n",
      "          [0.6431, 0.6549, 0.6667,  ..., 0.3686, 0.3765, 0.3804],\n",
      "          ...,\n",
      "          [0.1490, 0.1451, 0.1686,  ..., 0.1804, 0.1804, 0.1333],\n",
      "          [0.1373, 0.1412, 0.1647,  ..., 0.1686, 0.1765, 0.1255],\n",
      "          [0.1373, 0.1451, 0.1569,  ..., 0.1686, 0.1725, 0.1294]]],\n",
      "\n",
      "\n",
      "        [[[0.3647, 0.3647, 0.3647,  ..., 0.1765, 0.1725, 0.1686],\n",
      "          [0.3686, 0.3686, 0.3686,  ..., 0.1725, 0.1686, 0.1647],\n",
      "          [0.3725, 0.3725, 0.3725,  ..., 0.1569, 0.1529, 0.1451],\n",
      "          ...,\n",
      "          [0.4784, 0.5882, 0.7255,  ..., 0.0431, 0.0431, 0.0431],\n",
      "          [0.6353, 0.7490, 0.8157,  ..., 0.0431, 0.0471, 0.0471],\n",
      "          [0.7804, 0.8235, 0.8275,  ..., 0.0431, 0.0471, 0.0510]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(0.9952, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 0.9952067732810974\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.2980, 0.2941, 0.2941,  ..., 0.2235, 0.1529, 0.0902],\n",
      "          [0.2980, 0.2980, 0.2980,  ..., 0.1961, 0.1137, 0.0941],\n",
      "          [0.2941, 0.2941, 0.2980,  ..., 0.1765, 0.0980, 0.1020]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.4941, 0.4941, 0.4941,  ..., 0.1412, 0.1333, 0.1373],\n",
      "          [0.4941, 0.4941, 0.4941,  ..., 0.1333, 0.1412, 0.1333],\n",
      "          [0.4941, 0.4941, 0.4941,  ..., 0.1216, 0.1412, 0.1373]]],\n",
      "\n",
      "\n",
      "        [[[0.7451, 0.7451, 0.7412,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7451, 0.7451, 0.7412,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.7451, 0.7451, 0.7412,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0863, 0.1216, 0.1333,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.1333, 0.1333, 0.1294,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.1333, 0.1255, 0.1294,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.2235, 0.2157, 0.2275,  ..., 0.9412, 0.8588, 0.7529],\n",
      "          [0.3176, 0.3294, 0.3725,  ..., 0.9804, 0.9529, 0.8824],\n",
      "          [0.3529, 0.3765, 0.4000,  ..., 0.9843, 0.9725, 0.9569]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0275, 0.0353, 0.0471,  ..., 0.9843, 0.9922, 0.9922],\n",
      "          [0.0314, 0.0314, 0.0353,  ..., 0.9882, 0.9882, 0.9882],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.9882, 0.9882, 0.9882]]],\n",
      "\n",
      "\n",
      "        [[[0.4941, 0.4980, 0.5020,  ..., 1.0000, 0.9961, 0.9922],\n",
      "          [0.4980, 0.4980, 0.5020,  ..., 1.0000, 0.9961, 0.9922],\n",
      "          [0.5020, 0.5020, 0.5020,  ..., 1.0000, 0.9961, 0.9922],\n",
      "          ...,\n",
      "          [0.1765, 0.1804, 0.1765,  ..., 0.4745, 0.4902, 0.4824],\n",
      "          [0.1804, 0.1725, 0.1725,  ..., 0.4549, 0.4706, 0.4706],\n",
      "          [0.1725, 0.1686, 0.1569,  ..., 0.4471, 0.4588, 0.4627]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.2810, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.2809699773788452\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1529, 0.2118, 0.2157,  ..., 0.2078, 0.2039, 0.2000],\n",
      "          [0.1922, 0.2431, 0.2118,  ..., 0.2039, 0.2000, 0.1961],\n",
      "          [0.1882, 0.2314, 0.2039,  ..., 0.1961, 0.1961, 0.1922]]],\n",
      "\n",
      "\n",
      "        [[[0.2588, 0.2471, 0.2196,  ..., 0.3020, 0.2941, 0.3059],\n",
      "          [0.2627, 0.2510, 0.2235,  ..., 0.2980, 0.3020, 0.3098],\n",
      "          [0.2627, 0.2510, 0.2196,  ..., 0.2863, 0.3098, 0.3020],\n",
      "          ...,\n",
      "          [0.2824, 0.2706, 0.2706,  ..., 0.1333, 0.1333, 0.1216],\n",
      "          [0.2392, 0.2314, 0.2314,  ..., 0.1294, 0.1255, 0.1176],\n",
      "          [0.2196, 0.2275, 0.2392,  ..., 0.1255, 0.1176, 0.1216]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0627, 0.0471, 0.0667,  ..., 0.1255, 0.1216, 0.1216],\n",
      "          [0.1569, 0.0980, 0.0471,  ..., 0.1294, 0.1255, 0.1176],\n",
      "          [0.2549, 0.1843, 0.0980,  ..., 0.1294, 0.1294, 0.1216]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.1294, 0.1176, 0.0980],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1059, 0.0863, 0.0863],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0549, 0.0667, 0.0706],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2118, 0.3765, 0.7294],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1961, 0.3176, 0.6745],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1882, 0.1961, 0.4471]]],\n",
      "\n",
      "\n",
      "        [[[0.0941, 0.0980, 0.1020,  ..., 0.0471, 0.0431, 0.0392],\n",
      "          [0.7020, 0.7216, 0.7333,  ..., 0.3569, 0.3216, 0.2902],\n",
      "          [0.8431, 0.8627, 0.8784,  ..., 0.4157, 0.3686, 0.3412],\n",
      "          ...,\n",
      "          [0.5176, 0.5176, 0.5176,  ..., 0.1255, 0.1765, 0.1490],\n",
      "          [0.5098, 0.5098, 0.5098,  ..., 0.1529, 0.1451, 0.1176],\n",
      "          [0.5098, 0.5098, 0.5098,  ..., 0.1490, 0.1059, 0.1176]]],\n",
      "\n",
      "\n",
      "        [[[0.9451, 0.9373, 0.9373,  ..., 0.8353, 0.8431, 0.8471],\n",
      "          [0.9412, 0.9333, 0.9294,  ..., 0.8275, 0.8353, 0.8353],\n",
      "          [0.9333, 0.9333, 0.9333,  ..., 0.8235, 0.8275, 0.8353],\n",
      "          ...,\n",
      "          [0.2353, 0.2314, 0.2235,  ..., 0.2000, 0.1647, 0.1333],\n",
      "          [0.2314, 0.2275, 0.2157,  ..., 0.1765, 0.1451, 0.1137],\n",
      "          [0.2118, 0.2078, 0.2196,  ..., 0.1451, 0.1216, 0.1020]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.0562, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.0561779737472534\n",
      "\n",
      "tensor([[[[0.3608, 0.3882, 0.4353,  ..., 0.3137, 0.3098, 0.3059],\n",
      "          [0.3608, 0.3765, 0.4235,  ..., 0.3137, 0.3098, 0.3059],\n",
      "          [0.3569, 0.3569, 0.4078,  ..., 0.3137, 0.3098, 0.3059],\n",
      "          ...,\n",
      "          [0.1843, 0.1843, 0.2000,  ..., 0.1451, 0.0941, 0.0902],\n",
      "          [0.1804, 0.1961, 0.1961,  ..., 0.1255, 0.0863, 0.0980],\n",
      "          [0.1843, 0.1882, 0.1922,  ..., 0.1059, 0.0902, 0.1020]]],\n",
      "\n",
      "\n",
      "        [[[0.3569, 0.3412, 0.3608,  ..., 0.3216, 0.2863, 0.2353],\n",
      "          [0.3294, 0.3176, 0.3294,  ..., 0.2902, 0.2627, 0.2157],\n",
      "          [0.3098, 0.2902, 0.2980,  ..., 0.2902, 0.2745, 0.2392],\n",
      "          ...,\n",
      "          [0.3412, 0.3059, 0.1882,  ..., 0.0196, 0.0275, 0.0235],\n",
      "          [0.2745, 0.1725, 0.0941,  ..., 0.0196, 0.0275, 0.0275],\n",
      "          [0.1882, 0.0824, 0.0588,  ..., 0.0196, 0.0196, 0.0235]]],\n",
      "\n",
      "\n",
      "        [[[0.0275, 0.0235, 0.0275,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0157, 0.0157, 0.0157,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0078, 0.0078, 0.0118,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.2275, 0.2471, 0.2902,  ..., 0.0196, 0.0118, 0.0078],\n",
      "          [0.2588, 0.2627, 0.2588,  ..., 0.0196, 0.0157, 0.0078],\n",
      "          [0.2510, 0.2706, 0.2706,  ..., 0.0196, 0.0196, 0.0118]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0824, 0.0824, 0.0824,  ..., 0.2314, 0.2275, 0.2157],\n",
      "          [0.0902, 0.0863, 0.0863,  ..., 0.2392, 0.2314, 0.2275],\n",
      "          [0.0980, 0.0941, 0.0902,  ..., 0.2431, 0.2392, 0.2353],\n",
      "          ...,\n",
      "          [0.1608, 0.1765, 0.2078,  ..., 0.2078, 0.1961, 0.1922],\n",
      "          [0.1608, 0.1647, 0.1843,  ..., 0.2000, 0.1882, 0.1843],\n",
      "          [0.1451, 0.1647, 0.1725,  ..., 0.2000, 0.1882, 0.1843]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0941, 0.1098, 0.1176,  ..., 0.1412, 0.1373, 0.1333],\n",
      "          [0.1020, 0.1020, 0.1020,  ..., 0.1333, 0.1333, 0.1373],\n",
      "          [0.1059, 0.0941, 0.0941,  ..., 0.1333, 0.1373, 0.1373]]],\n",
      "\n",
      "\n",
      "        [[[0.2235, 0.2196, 0.2157,  ..., 0.1451, 0.1451, 0.1451],\n",
      "          [0.2000, 0.1961, 0.1922,  ..., 0.1647, 0.1686, 0.1686],\n",
      "          [0.1725, 0.1647, 0.1569,  ..., 0.3373, 0.3529, 0.3569],\n",
      "          ...,\n",
      "          [0.4824, 0.4667, 0.6000,  ..., 0.0471, 0.0471, 0.0510],\n",
      "          [0.5725, 0.6784, 0.7020,  ..., 0.0667, 0.0902, 0.0941],\n",
      "          [0.7020, 0.7059, 0.7294,  ..., 0.0941, 0.1098, 0.1137]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.5860, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.58600652217865\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0039, 0.0000],\n",
      "          [0.1804, 0.1804, 0.1804,  ..., 0.2471, 0.2471, 0.2431],\n",
      "          [0.6353, 0.6353, 0.6275,  ..., 0.8667, 0.8588, 0.8588],\n",
      "          ...,\n",
      "          [0.5216, 0.5216, 0.5216,  ..., 0.1490, 0.1490, 0.1294],\n",
      "          [0.5216, 0.5216, 0.5216,  ..., 0.1569, 0.1412, 0.1216],\n",
      "          [0.5255, 0.5255, 0.5216,  ..., 0.1529, 0.1412, 0.1294]]],\n",
      "\n",
      "\n",
      "        [[[0.3373, 0.3373, 0.3490,  ..., 0.5216, 0.5490, 0.5686],\n",
      "          [0.3333, 0.3373, 0.3451,  ..., 0.5333, 0.5529, 0.5804],\n",
      "          [0.3373, 0.3412, 0.3490,  ..., 0.5490, 0.5608, 0.5765],\n",
      "          ...,\n",
      "          [0.2471, 0.2431, 0.2353,  ..., 0.4000, 0.3843, 0.3765],\n",
      "          [0.2627, 0.2588, 0.2510,  ..., 0.4118, 0.3922, 0.3804],\n",
      "          [0.2745, 0.2745, 0.2667,  ..., 0.4235, 0.4078, 0.3843]]],\n",
      "\n",
      "\n",
      "        [[[0.5725, 0.7412, 0.9176,  ..., 0.0824, 0.0863, 0.0863],\n",
      "          [0.7490, 0.8314, 0.9059,  ..., 0.0824, 0.0863, 0.0863],\n",
      "          [0.8235, 0.8275, 0.8235,  ..., 0.0824, 0.0863, 0.0863],\n",
      "          ...,\n",
      "          [0.0549, 0.0588, 0.0471,  ..., 0.2941, 0.2745, 0.2549],\n",
      "          [0.0588, 0.0588, 0.0510,  ..., 0.2863, 0.2902, 0.2627],\n",
      "          [0.0549, 0.0549, 0.0510,  ..., 0.2784, 0.2863, 0.2431]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0078, 0.0078, 0.0235,  ..., 0.0196, 0.0196, 0.0039],\n",
      "          [0.0039, 0.0431, 0.3294,  ..., 0.1686, 0.0902, 0.0157],\n",
      "          [0.0039, 0.0510, 0.4078,  ..., 0.1490, 0.1020, 0.0235],\n",
      "          ...,\n",
      "          [0.0039, 0.0314, 0.2431,  ..., 0.1725, 0.4588, 0.1412],\n",
      "          [0.0039, 0.0235, 0.1765,  ..., 0.3412, 0.7725, 0.2078],\n",
      "          [0.0000, 0.0196, 0.1529,  ..., 0.4824, 0.6784, 0.1725]]],\n",
      "\n",
      "\n",
      "        [[[0.4196, 0.4235, 0.4196,  ..., 0.3765, 0.3765, 0.3765],\n",
      "          [0.4039, 0.4039, 0.4118,  ..., 0.3686, 0.3686, 0.3725],\n",
      "          [0.3686, 0.3725, 0.3765,  ..., 0.3725, 0.3725, 0.3765],\n",
      "          ...,\n",
      "          [0.0902, 0.0902, 0.0902,  ..., 0.0863, 0.0863, 0.0863],\n",
      "          [0.0902, 0.0902, 0.0902,  ..., 0.0941, 0.0941, 0.0941],\n",
      "          [0.0902, 0.0902, 0.0863,  ..., 0.1020, 0.1020, 0.0980]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0353, 0.0314, 0.0353,  ..., 0.5529, 0.5961, 0.6235],\n",
      "          [0.0314, 0.0275, 0.0314,  ..., 0.5412, 0.5843, 0.6275],\n",
      "          [0.0353, 0.0275, 0.0275,  ..., 0.5294, 0.5804, 0.6196]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.2965, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.2964872121810913\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0431, 0.0392, 0.0353,  ..., 0.0471, 0.0431, 0.0431],\n",
      "          [0.0431, 0.0392, 0.0392,  ..., 0.0431, 0.0471, 0.0510],\n",
      "          [0.0431, 0.0392, 0.0392,  ..., 0.0471, 0.0510, 0.0510]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.5765, 0.5725, 0.5725],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.5725, 0.5686, 0.5686],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.5725, 0.5725, 0.5725],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1176, 0.1255, 0.2275],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0863, 0.1373, 0.2078],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1804, 0.2275]]],\n",
      "\n",
      "\n",
      "        [[[0.7843, 0.7922, 0.7961,  ..., 0.5255, 0.5216, 0.5216],\n",
      "          [0.7843, 0.7922, 0.7961,  ..., 0.5059, 0.5176, 0.5255],\n",
      "          [0.7843, 0.7922, 0.7961,  ..., 0.4980, 0.5059, 0.5176],\n",
      "          ...,\n",
      "          [0.0980, 0.0706, 0.1569,  ..., 0.0941, 0.0863, 0.0824],\n",
      "          [0.0941, 0.0667, 0.1490,  ..., 0.0902, 0.0784, 0.0824],\n",
      "          [0.0980, 0.0667, 0.1412,  ..., 0.0941, 0.0784, 0.0784]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.7686, 0.7686, 0.7686,  ..., 0.1882, 0.2000, 0.2196],\n",
      "          [0.7686, 0.7686, 0.7686,  ..., 0.1961, 0.2118, 0.2196],\n",
      "          [0.7686, 0.7686, 0.7686,  ..., 0.1922, 0.2039, 0.2275]]],\n",
      "\n",
      "\n",
      "        [[[0.8118, 0.8118, 0.8118,  ..., 0.2745, 0.2784, 0.2824],\n",
      "          [0.8157, 0.8157, 0.8157,  ..., 0.2353, 0.2275, 0.2314],\n",
      "          [0.8196, 0.8196, 0.8078,  ..., 0.2392, 0.2431, 0.2353],\n",
      "          ...,\n",
      "          [0.3922, 0.3961, 0.3882,  ..., 0.1176, 0.1137, 0.1255],\n",
      "          [0.3529, 0.4000, 0.4314,  ..., 0.1137, 0.1020, 0.1098],\n",
      "          [0.2745, 0.3255, 0.3882,  ..., 0.1137, 0.0980, 0.0941]]],\n",
      "\n",
      "\n",
      "        [[[0.0078, 0.0078, 0.0235,  ..., 0.0196, 0.0196, 0.0039],\n",
      "          [0.0039, 0.0431, 0.3294,  ..., 0.1686, 0.0902, 0.0157],\n",
      "          [0.0039, 0.0510, 0.4078,  ..., 0.1490, 0.1020, 0.0235],\n",
      "          ...,\n",
      "          [0.0039, 0.0314, 0.2431,  ..., 0.1725, 0.4588, 0.1412],\n",
      "          [0.0039, 0.0235, 0.1765,  ..., 0.3412, 0.7725, 0.2078],\n",
      "          [0.0000, 0.0196, 0.1529,  ..., 0.4824, 0.6784, 0.1725]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.0596, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.0596234798431396\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.2510, 0.2471, 0.2431,  ..., 0.0196, 0.0039, 0.0039],\n",
      "          [0.2392, 0.2353, 0.2431,  ..., 0.0196, 0.0039, 0.0039],\n",
      "          [0.2275, 0.2275, 0.2353,  ..., 0.0196, 0.0039, 0.0039]]],\n",
      "\n",
      "\n",
      "        [[[0.0667, 0.0549, 0.0431,  ..., 0.0431, 0.0392, 0.0392],\n",
      "          [0.0667, 0.0549, 0.0431,  ..., 0.0549, 0.0431, 0.0353],\n",
      "          [0.0667, 0.0588, 0.0471,  ..., 0.0549, 0.0510, 0.0431],\n",
      "          ...,\n",
      "          [0.0588, 0.0824, 0.2314,  ..., 0.2196, 0.1922, 0.1725],\n",
      "          [0.0471, 0.1020, 0.1922,  ..., 0.2039, 0.1725, 0.1647],\n",
      "          [0.0667, 0.2157, 0.3569,  ..., 0.2078, 0.1686, 0.1608]]],\n",
      "\n",
      "\n",
      "        [[[0.1647, 0.1725, 0.1608,  ..., 0.8902, 0.6549, 0.2745],\n",
      "          [0.1608, 0.1647, 0.1608,  ..., 0.8549, 0.4784, 0.1961],\n",
      "          [0.1608, 0.1569, 0.1569,  ..., 0.8863, 0.5451, 0.2196],\n",
      "          ...,\n",
      "          [0.1490, 0.1608, 0.2235,  ..., 0.1373, 0.1373, 0.1804],\n",
      "          [0.1569, 0.1451, 0.2000,  ..., 0.1412, 0.1608, 0.1922],\n",
      "          [0.1529, 0.1608, 0.2118,  ..., 0.1412, 0.1725, 0.1725]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.7176, 0.7176, 0.7176,  ..., 0.2078, 0.2275, 0.2353],\n",
      "          [0.6784, 0.6863, 0.6902,  ..., 0.2118, 0.2275, 0.2353],\n",
      "          [0.5882, 0.6118, 0.6196,  ..., 0.2078, 0.2235, 0.2314],\n",
      "          ...,\n",
      "          [0.1373, 0.1216, 0.1098,  ..., 0.0745, 0.0549, 0.0667],\n",
      "          [0.3451, 0.3255, 0.2980,  ..., 0.0784, 0.0549, 0.0627],\n",
      "          [0.6941, 0.6980, 0.6863,  ..., 0.0784, 0.0588, 0.0627]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1412, 0.1412, 0.1255,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.1412, 0.1490, 0.1294,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.1294, 0.1529, 0.1333,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.2706, 0.4902, 0.6902,  ..., 0.6000, 0.5804, 0.5686],\n",
      "          [0.3490, 0.5686, 0.6824,  ..., 0.6667, 0.6588, 0.6588],\n",
      "          [0.4588, 0.6157, 0.6078,  ..., 0.7020, 0.6941, 0.6824],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.3249, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.3249300718307495\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.0118, 0.0235, 0.0706,  ..., 0.5412, 0.4667, 0.4275],\n",
      "          [0.0314, 0.0353, 0.0471,  ..., 0.5529, 0.4745, 0.4314],\n",
      "          [0.0510, 0.0706, 0.0392,  ..., 0.5529, 0.4745, 0.4353]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0196, 0.0196, 0.0196],\n",
      "          ...,\n",
      "          [0.0275, 0.0275, 0.0275,  ..., 0.6157, 0.5843, 0.6196],\n",
      "          [0.0157, 0.0196, 0.0196,  ..., 0.7137, 0.6784, 0.6627],\n",
      "          [0.0196, 0.0196, 0.0157,  ..., 0.7451, 0.7059, 0.6863]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1961, 0.0980, 0.0667,  ..., 0.0235, 0.0196, 0.0235],\n",
      "          [0.0667, 0.0627, 0.0588,  ..., 0.0235, 0.0196, 0.0196],\n",
      "          [0.0627, 0.0588, 0.0588,  ..., 0.0235, 0.0235, 0.0235]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0157, 0.0118, 0.0118,  ..., 0.0118, 0.0118, 0.0078],\n",
      "          [0.1176, 0.1098, 0.1059,  ..., 0.1137, 0.0941, 0.0824],\n",
      "          ...,\n",
      "          [0.1451, 0.1451, 0.1490,  ..., 0.6235, 0.5647, 0.5490],\n",
      "          [0.1373, 0.1490, 0.1490,  ..., 0.5608, 0.5098, 0.4941],\n",
      "          [0.1333, 0.1412, 0.1451,  ..., 0.5333, 0.4784, 0.4510]]],\n",
      "\n",
      "\n",
      "        [[[0.3804, 0.3804, 0.3804,  ..., 0.4157, 0.4157, 0.4157],\n",
      "          [0.6980, 0.6941, 0.6980,  ..., 0.7647, 0.7647, 0.7686],\n",
      "          [0.7098, 0.7098, 0.7137,  ..., 0.7765, 0.7765, 0.7765],\n",
      "          ...,\n",
      "          [0.4549, 0.4471, 0.4353,  ..., 0.3255, 0.3333, 0.3020],\n",
      "          [0.4510, 0.4353, 0.4275,  ..., 0.3020, 0.3176, 0.2980],\n",
      "          [0.4431, 0.4353, 0.4275,  ..., 0.2824, 0.2941, 0.2824]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.1137, 0.1098, 0.1098,  ..., 0.1882, 0.1647, 0.0863],\n",
      "          [0.5137, 0.5098, 0.5020,  ..., 0.8627, 0.7608, 0.4275],\n",
      "          ...,\n",
      "          [0.2431, 0.2392, 0.2392,  ..., 0.1333, 0.1922, 0.2196],\n",
      "          [0.2118, 0.2235, 0.2392,  ..., 0.1608, 0.2118, 0.2118],\n",
      "          [0.1529, 0.1882, 0.2235,  ..., 0.1765, 0.2039, 0.1961]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.1389, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.1388909816741943\n",
      "\n",
      "tensor([[[[0.0039, 0.0000, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.1529, 0.1608, 0.1725,  ..., 0.0196, 0.0235, 0.0314],\n",
      "          [0.6549, 0.6902, 0.7255,  ..., 0.0824, 0.0980, 0.1176],\n",
      "          ...,\n",
      "          [0.6000, 0.7765, 0.8627,  ..., 0.2157, 0.2235, 0.2314],\n",
      "          [0.2745, 0.4667, 0.7765,  ..., 0.2078, 0.2196, 0.2314],\n",
      "          [0.2118, 0.2314, 0.5647,  ..., 0.2078, 0.2157, 0.2235]]],\n",
      "\n",
      "\n",
      "        [[[0.2196, 0.2196, 0.2235,  ..., 0.4627, 0.4431, 0.4039],\n",
      "          [0.2157, 0.2196, 0.2235,  ..., 0.2627, 0.2510, 0.2353],\n",
      "          [0.2196, 0.2353, 0.2510,  ..., 0.2039, 0.2039, 0.1882],\n",
      "          ...,\n",
      "          [0.2196, 0.2118, 0.2039,  ..., 0.3529, 0.3373, 0.3922],\n",
      "          [0.2118, 0.2000, 0.1961,  ..., 0.3922, 0.3098, 0.3412],\n",
      "          [0.1804, 0.1882, 0.2039,  ..., 0.3373, 0.3333, 0.3725]]],\n",
      "\n",
      "\n",
      "        [[[0.0902, 0.0745, 0.0667,  ..., 0.2314, 0.0314, 0.0000],\n",
      "          [0.1765, 0.1569, 0.1373,  ..., 0.4745, 0.0627, 0.0000],\n",
      "          [0.1765, 0.1569, 0.1373,  ..., 0.4824, 0.0627, 0.0039],\n",
      "          ...,\n",
      "          [0.1373, 0.1059, 0.0863,  ..., 0.2980, 0.0353, 0.0039],\n",
      "          [0.1451, 0.1412, 0.1176,  ..., 0.2824, 0.0353, 0.0039],\n",
      "          [0.1608, 0.1490, 0.1412,  ..., 0.2706, 0.0353, 0.0039]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1961, 0.1922, 0.1843,  ..., 0.1843, 0.1490, 0.0941],\n",
      "          [0.4157, 0.3176, 0.2078,  ..., 0.1686, 0.1098, 0.0784],\n",
      "          [0.5333, 0.5059, 0.4118,  ..., 0.1373, 0.0745, 0.0980]]],\n",
      "\n",
      "\n",
      "        [[[0.9647, 0.9647, 0.9647,  ..., 0.6745, 0.6745, 0.6627],\n",
      "          [0.9608, 0.9608, 0.9608,  ..., 0.4745, 0.4314, 0.3961],\n",
      "          [0.9569, 0.9569, 0.9569,  ..., 0.2510, 0.2627, 0.2784],\n",
      "          ...,\n",
      "          [0.6275, 0.3451, 0.1765,  ..., 0.1373, 0.1255, 0.1137],\n",
      "          [0.4157, 0.2000, 0.1529,  ..., 0.1294, 0.1255, 0.1098],\n",
      "          [0.2510, 0.1608, 0.1216,  ..., 0.1216, 0.1176, 0.1020]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0824, 0.0784, 0.0627],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0824, 0.0784, 0.0706],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0863, 0.0824, 0.0784]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.3193, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.3192570209503174\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.2392, 0.2549, 0.2588,  ..., 0.5647, 0.8431, 0.8588],\n",
      "          [0.2510, 0.2118, 0.2000,  ..., 0.2000, 0.6667, 0.8078],\n",
      "          [0.2980, 0.2588, 0.1922,  ..., 0.0431, 0.2745, 0.6118]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0000, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.2157, 0.2039, 0.1961,  ..., 0.2980, 0.2706, 0.2706],\n",
      "          [0.2431, 0.2392, 0.2314,  ..., 0.3059, 0.3216, 0.3216],\n",
      "          [0.2588, 0.2588, 0.2549,  ..., 0.3137, 0.3451, 0.3451]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.7490, 0.7961, 0.8157,  ..., 0.6588, 0.6510, 0.6863],\n",
      "          [0.7490, 0.7922, 0.8118,  ..., 0.6549, 0.6314, 0.6510],\n",
      "          [0.7451, 0.7961, 0.8118,  ..., 0.6392, 0.6157, 0.6353],\n",
      "          ...,\n",
      "          [0.0118, 0.0118, 0.0157,  ..., 0.6431, 0.6157, 0.4824],\n",
      "          [0.0118, 0.0118, 0.0118,  ..., 0.6431, 0.5961, 0.4824],\n",
      "          [0.0118, 0.0118, 0.0118,  ..., 0.6510, 0.5961, 0.4941]]],\n",
      "\n",
      "\n",
      "        [[[0.0549, 0.0627, 0.0941,  ..., 0.1020, 0.1059, 0.0549],\n",
      "          [0.0510, 0.0588, 0.0902,  ..., 0.1020, 0.1020, 0.0549],\n",
      "          [0.0471, 0.0588, 0.0902,  ..., 0.1059, 0.1059, 0.0588],\n",
      "          ...,\n",
      "          [0.1882, 0.1961, 0.1961,  ..., 0.1373, 0.2039, 0.2980],\n",
      "          [0.1765, 0.1882, 0.1961,  ..., 0.1255, 0.1882, 0.2863],\n",
      "          [0.1647, 0.1804, 0.1843,  ..., 0.1176, 0.1882, 0.2902]]],\n",
      "\n",
      "\n",
      "        [[[0.2784, 0.2824, 0.2784,  ..., 0.6157, 0.6118, 0.6118],\n",
      "          [0.2784, 0.2784, 0.2784,  ..., 0.6157, 0.6118, 0.6118],\n",
      "          [0.2784, 0.2745, 0.2784,  ..., 0.6157, 0.6157, 0.5961],\n",
      "          ...,\n",
      "          [0.0824, 0.0745, 0.0784,  ..., 0.0980, 0.0941, 0.0902],\n",
      "          [0.0824, 0.0745, 0.0784,  ..., 0.0941, 0.0941, 0.0941],\n",
      "          [0.0824, 0.0784, 0.0784,  ..., 0.0863, 0.0863, 0.0902]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.1274, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.1274425983428955\n",
      "\n",
      "tensor([[[[0.1608, 0.1176, 0.1608,  ..., 0.1490, 0.1137, 0.0745],\n",
      "          [0.1333, 0.1176, 0.1647,  ..., 0.1333, 0.0941, 0.0549],\n",
      "          [0.1137, 0.1176, 0.1647,  ..., 0.1098, 0.0706, 0.0431],\n",
      "          ...,\n",
      "          [0.3922, 0.3922, 0.3961,  ..., 0.4784, 0.5020, 0.5216],\n",
      "          [0.3804, 0.3843, 0.3882,  ..., 0.5059, 0.5059, 0.5098],\n",
      "          [0.3725, 0.3804, 0.3843,  ..., 0.5020, 0.4863, 0.4627]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0235, 0.0314, 0.0392,  ..., 0.0706, 0.0667, 0.0627],\n",
      "          [0.0196, 0.0275, 0.0392,  ..., 0.0706, 0.0667, 0.0627],\n",
      "          [0.0157, 0.0235, 0.0392,  ..., 0.0627, 0.0549, 0.0667]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0784, 0.1020, 0.1373,  ..., 0.2196, 0.2196, 0.2078],\n",
      "          [0.1255, 0.1098, 0.1451,  ..., 0.2196, 0.2118, 0.2118],\n",
      "          [0.1647, 0.1490, 0.1686,  ..., 0.2078, 0.2078, 0.2078]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.3529, 0.3569, 0.3647,  ..., 0.2588, 0.2667, 0.2745],\n",
      "          [0.4118, 0.4157, 0.4392,  ..., 0.2706, 0.2784, 0.2824],\n",
      "          [0.5686, 0.5765, 0.5961,  ..., 0.2902, 0.2902, 0.2941],\n",
      "          ...,\n",
      "          [0.0863, 0.0667, 0.0902,  ..., 0.0980, 0.0941, 0.0902],\n",
      "          [0.0980, 0.0824, 0.1020,  ..., 0.1020, 0.1020, 0.0980],\n",
      "          [0.0941, 0.0863, 0.1059,  ..., 0.1059, 0.1059, 0.1059]]],\n",
      "\n",
      "\n",
      "        [[[0.3294, 0.5059, 0.6706,  ..., 0.7804, 0.7020, 0.5843],\n",
      "          [0.2000, 0.4431, 0.6510,  ..., 0.7373, 0.6627, 0.5294],\n",
      "          [0.2235, 0.4314, 0.5961,  ..., 0.6549, 0.5804, 0.4745],\n",
      "          ...,\n",
      "          [0.7922, 0.7882, 0.7882,  ..., 0.7490, 0.6784, 0.5804],\n",
      "          [0.7922, 0.7882, 0.7843,  ..., 0.7255, 0.6314, 0.4980],\n",
      "          [0.7882, 0.7882, 0.7843,  ..., 0.7020, 0.5882, 0.4235]]],\n",
      "\n",
      "\n",
      "        [[[0.8431, 0.8431, 0.8431,  ..., 0.8510, 0.8431, 0.8431],\n",
      "          [0.8471, 0.8471, 0.8471,  ..., 0.8510, 0.8471, 0.8471],\n",
      "          [0.8471, 0.8471, 0.8510,  ..., 0.8510, 0.8471, 0.8510],\n",
      "          ...,\n",
      "          [0.0824, 0.0863, 0.0902,  ..., 0.1176, 0.1216, 0.1216],\n",
      "          [0.0784, 0.0863, 0.0824,  ..., 0.1216, 0.1255, 0.1255],\n",
      "          [0.0902, 0.0863, 0.0863,  ..., 0.1255, 0.1255, 0.1255]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.1991, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.1990737915039062\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1098, 0.1020, 0.1059,  ..., 0.1333, 0.1216, 0.1216],\n",
      "          [0.1059, 0.1020, 0.1059,  ..., 0.0784, 0.0706, 0.0745],\n",
      "          [0.1059, 0.1059, 0.1059,  ..., 0.1059, 0.1098, 0.1059]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1569, 0.1529, 0.1529],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1490, 0.1373, 0.1333],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1216, 0.1098, 0.1020]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.1843, 0.1804, 0.1725,  ..., 0.1176, 0.1255, 0.1255],\n",
      "          [0.1843, 0.1804, 0.1725,  ..., 0.1137, 0.1176, 0.1176],\n",
      "          [0.1804, 0.1804, 0.1686,  ..., 0.1098, 0.1059, 0.1059]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0039],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0941, 0.1020, 0.0980,  ..., 0.1098, 0.1922, 0.2275],\n",
      "          [0.0745, 0.0941, 0.1020,  ..., 0.1020, 0.1804, 0.2235],\n",
      "          [0.0627, 0.0863, 0.1020,  ..., 0.0941, 0.1686, 0.2118]]],\n",
      "\n",
      "\n",
      "        [[[0.9529, 0.9686, 0.9882,  ..., 0.7373, 0.7137, 0.6902],\n",
      "          [0.9569, 0.9686, 0.9882,  ..., 0.7373, 0.7137, 0.6941],\n",
      "          [0.9608, 0.9686, 0.9882,  ..., 0.7294, 0.7137, 0.7020],\n",
      "          ...,\n",
      "          [0.1137, 0.1098, 0.1059,  ..., 0.6314, 0.6118, 0.6196],\n",
      "          [0.1176, 0.1098, 0.1059,  ..., 0.6392, 0.6118, 0.6157],\n",
      "          [0.1137, 0.1059, 0.1020,  ..., 0.6431, 0.6235, 0.6196]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1843, 0.1882, 0.1922,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.1804, 0.1882, 0.1843,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.1843, 0.1843, 0.1804,  ..., 0.0000, 0.0000, 0.0000]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.0229, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.0228880643844604\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0549, 0.0549, 0.0588,  ..., 0.0824, 0.0784, 0.0784],\n",
      "          ...,\n",
      "          [0.1333, 0.1412, 0.1412,  ..., 0.0627, 0.0510, 0.0471],\n",
      "          [0.1333, 0.1373, 0.1412,  ..., 0.0588, 0.0471, 0.0431],\n",
      "          [0.1333, 0.1412, 0.1451,  ..., 0.0549, 0.0471, 0.0471]]],\n",
      "\n",
      "\n",
      "        [[[0.7373, 0.7725, 0.8000,  ..., 0.3216, 0.2824, 0.2471],\n",
      "          [0.6627, 0.7176, 0.7647,  ..., 0.3255, 0.2902, 0.2588],\n",
      "          [0.5686, 0.6353, 0.7020,  ..., 0.3333, 0.2980, 0.2667],\n",
      "          ...,\n",
      "          [0.3255, 0.3255, 0.3176,  ..., 0.4157, 0.4157, 0.4314],\n",
      "          [0.3098, 0.3137, 0.3059,  ..., 0.4314, 0.4510, 0.4745],\n",
      "          [0.2980, 0.3020, 0.2980,  ..., 0.4471, 0.4863, 0.5294]]],\n",
      "\n",
      "\n",
      "        [[[0.0118, 0.0118, 0.0118,  ..., 0.0353, 0.0314, 0.0275],\n",
      "          [0.0157, 0.0196, 0.0235,  ..., 0.0510, 0.0510, 0.0431],\n",
      "          [0.0157, 0.0235, 0.0275,  ..., 0.0510, 0.0549, 0.0510],\n",
      "          ...,\n",
      "          [0.1176, 0.1216, 0.1098,  ..., 0.0941, 0.0627, 0.0314],\n",
      "          [0.1255, 0.1137, 0.1137,  ..., 0.0902, 0.0549, 0.0196],\n",
      "          [0.1176, 0.1098, 0.1098,  ..., 0.0824, 0.0588, 0.0196]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.3490, 0.3255, 0.2392,  ..., 0.4314, 0.3843, 0.1725],\n",
      "          [0.3686, 0.3451, 0.2667,  ..., 0.4275, 0.3725, 0.1765],\n",
      "          [0.3804, 0.3608, 0.3216,  ..., 0.4157, 0.3569, 0.1725]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1059, 0.1294, 0.1333,  ..., 0.1725, 0.1569, 0.1686],\n",
      "          [0.0824, 0.1098, 0.1255,  ..., 0.1686, 0.1529, 0.1686],\n",
      "          [0.0824, 0.0941, 0.1216,  ..., 0.1647, 0.1569, 0.1647]]],\n",
      "\n",
      "\n",
      "        [[[0.6667, 0.6824, 0.6863,  ..., 0.4235, 0.4392, 0.5490],\n",
      "          [0.6706, 0.6667, 0.6784,  ..., 0.4431, 0.4392, 0.5137],\n",
      "          [0.6627, 0.6549, 0.6667,  ..., 0.4824, 0.4667, 0.4588],\n",
      "          ...,\n",
      "          [0.1451, 0.1490, 0.1569,  ..., 0.7922, 0.7490, 0.7529],\n",
      "          [0.1451, 0.1490, 0.1569,  ..., 0.7490, 0.7373, 0.7725],\n",
      "          [0.1490, 0.1529, 0.1608,  ..., 0.7255, 0.7373, 0.7843]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.3088, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.30881929397583\n",
      "\n",
      "tensor([[[[0.2196, 0.2196, 0.2196,  ..., 0.2157, 0.2196, 0.2196],\n",
      "          [0.2196, 0.2196, 0.2196,  ..., 0.2157, 0.2196, 0.2196],\n",
      "          [0.2196, 0.2196, 0.2196,  ..., 0.2157, 0.2196, 0.2196],\n",
      "          ...,\n",
      "          [0.1725, 0.1647, 0.1569,  ..., 0.1686, 0.1608, 0.1529],\n",
      "          [0.1686, 0.1569, 0.1490,  ..., 0.1608, 0.1529, 0.1412],\n",
      "          [0.1647, 0.1529, 0.1412,  ..., 0.1529, 0.1373, 0.1255]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0039, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0078, 0.0078, 0.0078,  ..., 0.0039, 0.0000, 0.0039],\n",
      "          [0.0941, 0.0824, 0.0784,  ..., 0.0392, 0.0353, 0.0353],\n",
      "          ...,\n",
      "          [0.1725, 0.1686, 0.1451,  ..., 0.0980, 0.0902, 0.0941],\n",
      "          [0.1608, 0.1373, 0.1255,  ..., 0.0980, 0.0941, 0.0941],\n",
      "          [0.1255, 0.1137, 0.1176,  ..., 0.1020, 0.1020, 0.1020]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1922, 0.1843, 0.1882,  ..., 0.1804, 0.1647, 0.1529],\n",
      "          [0.1882, 0.1804, 0.1882,  ..., 0.1804, 0.1647, 0.1529],\n",
      "          [0.1843, 0.1843, 0.1922,  ..., 0.1804, 0.1529, 0.1490]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0510, 0.0431, 0.0431,  ..., 0.0118, 0.0118, 0.0118],\n",
      "          [0.0510, 0.0431, 0.0431,  ..., 0.0118, 0.0118, 0.0118],\n",
      "          [0.0431, 0.0392, 0.0392,  ..., 0.0157, 0.0157, 0.0157],\n",
      "          ...,\n",
      "          [0.3451, 0.3608, 0.3647,  ..., 0.1843, 0.1490, 0.1255],\n",
      "          [0.3529, 0.3686, 0.3608,  ..., 0.1451, 0.1216, 0.1176],\n",
      "          [0.3725, 0.3686, 0.3529,  ..., 0.1137, 0.1059, 0.1137]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0235, 0.0314, 0.0392,  ..., 0.0706, 0.0667, 0.0627],\n",
      "          [0.0196, 0.0275, 0.0392,  ..., 0.0706, 0.0667, 0.0627],\n",
      "          [0.0157, 0.0235, 0.0392,  ..., 0.0627, 0.0549, 0.0667]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.4706, 0.3098, 0.1569,  ..., 0.2667, 0.3137, 0.3216],\n",
      "          [0.3412, 0.1765, 0.1216,  ..., 0.2275, 0.2824, 0.3059],\n",
      "          [0.2627, 0.2078, 0.2902,  ..., 0.2118, 0.2549, 0.2980]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(0.9813, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 0.9812979698181152\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1569, 0.1608, 0.1529,  ..., 0.0863, 0.0902, 0.1176],\n",
      "          [0.1451, 0.1490, 0.1451,  ..., 0.0784, 0.1059, 0.1490],\n",
      "          [0.1373, 0.1412, 0.1412,  ..., 0.0941, 0.1373, 0.1725]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.5765, 0.5569, 0.5451,  ..., 0.3569, 0.3412, 0.3176],\n",
      "          [0.5490, 0.5529, 0.6078,  ..., 0.4902, 0.4314, 0.4353],\n",
      "          [0.5412, 0.6431, 0.8275,  ..., 0.7922, 0.6588, 0.5373]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.4392, 0.4078, 0.3804,  ..., 0.2235, 0.2157, 0.2157],\n",
      "          [0.4078, 0.4157, 0.4039,  ..., 0.2314, 0.2118, 0.2078],\n",
      "          [0.4078, 0.4118, 0.4078,  ..., 0.2392, 0.2196, 0.2000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0039, 0.0588,  ..., 0.1843, 0.1882, 0.1843],\n",
      "          [0.0039, 0.0039, 0.0627,  ..., 0.1922, 0.1961, 0.1804],\n",
      "          [0.0000, 0.0039, 0.0588,  ..., 0.2118, 0.2078, 0.1765],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0549,  ..., 0.0667, 0.0588, 0.0588],\n",
      "          [0.0000, 0.0039, 0.0588,  ..., 0.0863, 0.0627, 0.0588],\n",
      "          [0.0039, 0.0039, 0.0549,  ..., 0.0863, 0.0588, 0.0627]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.2353, 0.2392, 0.2471,  ..., 0.6863, 0.7294, 0.5961],\n",
      "          [0.2275, 0.2314, 0.2392,  ..., 0.6902, 0.7176, 0.7176],\n",
      "          [0.2235, 0.2275, 0.2353,  ..., 0.7843, 0.6118, 0.6039]]],\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0039, 0.0039,  ..., 0.0196, 0.0157, 0.0157],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0392, 0.0314, 0.0314],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0392, 0.0314, 0.0314],\n",
      "          ...,\n",
      "          [0.0471, 0.0471, 0.0549,  ..., 0.0745, 0.0510, 0.1137],\n",
      "          [0.0588, 0.0471, 0.0549,  ..., 0.0471, 0.0902, 0.1490],\n",
      "          [0.0431, 0.0431, 0.0510,  ..., 0.0588, 0.1294, 0.1725]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.4369, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.436926245689392\n",
      "\n",
      "tensor([[[[0.0039, 0.0039, 0.0039,  ..., 0.7843, 0.7843, 0.7804],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.7882, 0.7804, 0.7608],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.7961, 0.7804, 0.7451],\n",
      "          ...,\n",
      "          [0.0000, 0.0039, 0.0039,  ..., 0.5294, 0.6706, 0.7490],\n",
      "          [0.0000, 0.0039, 0.0039,  ..., 0.4392, 0.5765, 0.6706],\n",
      "          [0.0039, 0.0000, 0.0039,  ..., 0.3686, 0.4667, 0.5490]]],\n",
      "\n",
      "\n",
      "        [[[0.3725, 0.3804, 0.3804,  ..., 0.3882, 0.4000, 0.3961],\n",
      "          [0.3765, 0.3804, 0.3804,  ..., 0.3608, 0.3765, 0.3843],\n",
      "          [0.3804, 0.3765, 0.3725,  ..., 0.3529, 0.3647, 0.3765],\n",
      "          ...,\n",
      "          [0.1059, 0.1216, 0.1373,  ..., 0.2196, 0.2784, 0.3569],\n",
      "          [0.1176, 0.1333, 0.1333,  ..., 0.1412, 0.1569, 0.2039],\n",
      "          [0.1255, 0.1373, 0.1333,  ..., 0.1373, 0.1333, 0.1412]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0392, 0.0471, 0.0588,  ..., 0.0471, 0.0471, 0.0431],\n",
      "          [0.0431, 0.0471, 0.0510,  ..., 0.0510, 0.0510, 0.0431],\n",
      "          [0.0510, 0.0510, 0.0549,  ..., 0.0431, 0.0392, 0.0431]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.2588, 0.2549, 0.2549,  ..., 0.2431, 0.2471, 0.2431],\n",
      "          [0.2784, 0.2745, 0.2745,  ..., 0.2471, 0.2510, 0.2471],\n",
      "          [0.2980, 0.2941, 0.2941,  ..., 0.2706, 0.2745, 0.2706],\n",
      "          ...,\n",
      "          [0.3294, 0.3059, 0.2549,  ..., 0.2745, 0.2745, 0.2784],\n",
      "          [0.3882, 0.3412, 0.2549,  ..., 0.2745, 0.2784, 0.2745],\n",
      "          [0.3216, 0.2588, 0.2157,  ..., 0.2784, 0.2667, 0.2471]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.9882, 0.9882, 0.9765,  ..., 0.2196, 0.2275, 0.2196],\n",
      "          [1.0000, 0.9961, 0.9843,  ..., 0.2196, 0.2196, 0.2157],\n",
      "          [1.0000, 0.9961, 0.9882,  ..., 0.2157, 0.2118, 0.2118]]],\n",
      "\n",
      "\n",
      "        [[[0.3843, 0.4510, 0.4902,  ..., 0.0745, 0.0863, 0.0980],\n",
      "          [0.3961, 0.4588, 0.4980,  ..., 0.0549, 0.0549, 0.0588],\n",
      "          [0.4078, 0.4706, 0.5098,  ..., 0.0549, 0.0471, 0.0471],\n",
      "          ...,\n",
      "          [0.4941, 0.5059, 0.5059,  ..., 0.6392, 0.6431, 0.6627],\n",
      "          [0.4941, 0.4784, 0.4549,  ..., 0.6863, 0.6745, 0.6863],\n",
      "          [0.3412, 0.2863, 0.2314,  ..., 0.6588, 0.6314, 0.6196]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.2595, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.2594646215438843\n",
      "\n",
      "tensor([[[[0.3843, 0.3647, 0.3020,  ..., 0.1490, 0.1490, 0.1451],\n",
      "          [0.3020, 0.2706, 0.2157,  ..., 0.1451, 0.1608, 0.1608],\n",
      "          [0.2000, 0.1804, 0.1490,  ..., 0.1529, 0.1529, 0.1490],\n",
      "          ...,\n",
      "          [0.1255, 0.1255, 0.1216,  ..., 0.1294, 0.1255, 0.1137],\n",
      "          [0.1137, 0.1020, 0.0902,  ..., 0.1333, 0.1333, 0.1294],\n",
      "          [0.1059, 0.1020, 0.0941,  ..., 0.1333, 0.1373, 0.1412]]],\n",
      "\n",
      "\n",
      "        [[[0.8157, 0.8157, 0.8196,  ..., 0.2824, 0.3647, 0.4667],\n",
      "          [0.8039, 0.8157, 0.8235,  ..., 0.5373, 0.5686, 0.6039],\n",
      "          [0.8078, 0.8157, 0.8235,  ..., 0.5647, 0.5098, 0.4392],\n",
      "          ...,\n",
      "          [0.0157, 0.0157, 0.0235,  ..., 0.0392, 0.0157, 0.0078],\n",
      "          [0.0078, 0.0118, 0.0196,  ..., 0.0157, 0.0078, 0.0078],\n",
      "          [0.0039, 0.0078, 0.0118,  ..., 0.0157, 0.0078, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1843, 0.1843, 0.1882,  ..., 0.1451, 0.1451, 0.1451],\n",
      "          [0.1882, 0.1882, 0.1922,  ..., 0.1490, 0.1529, 0.1490],\n",
      "          [0.1882, 0.1882, 0.1922,  ..., 0.1529, 0.1569, 0.1490]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1412, 0.1412, 0.1412,  ..., 0.4275, 0.4275, 0.4353],\n",
      "          [0.1333, 0.1373, 0.1412,  ..., 0.4275, 0.4314, 0.4353],\n",
      "          [0.1176, 0.1294, 0.1412,  ..., 0.4275, 0.4275, 0.4353]]],\n",
      "\n",
      "\n",
      "        [[[0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0157, 0.0157],\n",
      "          [0.0118, 0.0118, 0.0118,  ..., 0.0078, 0.0078, 0.0118],\n",
      "          [0.0118, 0.0118, 0.0118,  ..., 0.0118, 0.0078, 0.0078],\n",
      "          ...,\n",
      "          [0.0627, 0.0549, 0.0510,  ..., 0.0392, 0.0471, 0.0471],\n",
      "          [0.0549, 0.0510, 0.0510,  ..., 0.0431, 0.0471, 0.0471],\n",
      "          [0.0510, 0.0510, 0.0510,  ..., 0.0471, 0.0471, 0.0471]]],\n",
      "\n",
      "\n",
      "        [[[0.5059, 0.5059, 0.5098,  ..., 0.5098, 0.5098, 0.5098],\n",
      "          [0.5098, 0.5098, 0.5098,  ..., 0.5098, 0.5098, 0.5098],\n",
      "          [0.5176, 0.5176, 0.5176,  ..., 0.5176, 0.5137, 0.5176],\n",
      "          ...,\n",
      "          [0.1216, 0.1333, 0.1294,  ..., 0.2471, 0.2235, 0.2275],\n",
      "          [0.1176, 0.1255, 0.1176,  ..., 0.5373, 0.2667, 0.2157],\n",
      "          [0.1137, 0.1255, 0.1255,  ..., 0.7333, 0.4706, 0.2157]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.3941, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.394087314605713\n",
      "\n",
      "tensor([[[[0.7569, 0.7608, 0.7725,  ..., 0.5490, 0.6784, 0.7412],\n",
      "          [0.7451, 0.7529, 0.7686,  ..., 0.5529, 0.6824, 0.7373],\n",
      "          [0.7373, 0.7490, 0.7765,  ..., 0.5608, 0.6863, 0.7333],\n",
      "          ...,\n",
      "          [0.1176, 0.1176, 0.1176,  ..., 0.1137, 0.1137, 0.1137],\n",
      "          [0.1176, 0.1176, 0.1176,  ..., 0.1137, 0.1176, 0.1137],\n",
      "          [0.1176, 0.1176, 0.1176,  ..., 0.1216, 0.1216, 0.1176]]],\n",
      "\n",
      "\n",
      "        [[[0.7686, 0.7686, 0.7686,  ..., 0.7765, 0.7804, 0.7804],\n",
      "          [0.7686, 0.7686, 0.7686,  ..., 0.7804, 0.7843, 0.7843],\n",
      "          [0.7686, 0.7686, 0.7686,  ..., 0.7804, 0.7843, 0.7843],\n",
      "          ...,\n",
      "          [0.2275, 0.2706, 0.2784,  ..., 0.4157, 0.4118, 0.4392],\n",
      "          [0.1333, 0.2039, 0.2549,  ..., 0.3961, 0.4039, 0.4118],\n",
      "          [0.0353, 0.0980, 0.1843,  ..., 0.3804, 0.3961, 0.4118]]],\n",
      "\n",
      "\n",
      "        [[[0.6000, 0.6196, 0.6118,  ..., 0.0431, 0.0667, 0.1137],\n",
      "          [0.6627, 0.6784, 0.6510,  ..., 0.0353, 0.0588, 0.1020],\n",
      "          [0.6235, 0.6431, 0.5922,  ..., 0.0314, 0.0549, 0.1020],\n",
      "          ...,\n",
      "          [0.1412, 0.1490, 0.1608,  ..., 0.0353, 0.0471, 0.0510],\n",
      "          [0.1333, 0.1569, 0.1765,  ..., 0.0314, 0.0392, 0.0431],\n",
      "          [0.1294, 0.1451, 0.1647,  ..., 0.0392, 0.0431, 0.0510]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0078, 0.1020, 0.3451,  ..., 0.3373, 0.3412, 0.3373],\n",
      "          [0.0078, 0.1020, 0.3412,  ..., 0.3412, 0.3373, 0.3333],\n",
      "          [0.0078, 0.0980, 0.3333,  ..., 0.3412, 0.3412, 0.3412],\n",
      "          ...,\n",
      "          [0.0000, 0.0275, 0.1020,  ..., 0.1255, 0.1451, 0.1451],\n",
      "          [0.0039, 0.0196, 0.0902,  ..., 0.1725, 0.1647, 0.1373],\n",
      "          [0.0039, 0.0196, 0.1137,  ..., 0.1529, 0.1137, 0.0745]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.8118, 0.8118, 0.8118,  ..., 0.2745, 0.2784, 0.2824],\n",
      "          [0.8157, 0.8157, 0.8157,  ..., 0.2353, 0.2275, 0.2314],\n",
      "          [0.8196, 0.8196, 0.8078,  ..., 0.2392, 0.2431, 0.2353],\n",
      "          ...,\n",
      "          [0.3922, 0.3961, 0.3882,  ..., 0.1176, 0.1137, 0.1255],\n",
      "          [0.3529, 0.4000, 0.4314,  ..., 0.1137, 0.1020, 0.1098],\n",
      "          [0.2745, 0.3255, 0.3882,  ..., 0.1137, 0.0980, 0.0941]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.1615, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.1615071296691895\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.2078, 0.2039, 0.2000,  ..., 0.0078, 0.0078, 0.0078],\n",
      "          [0.2078, 0.1961, 0.2039,  ..., 0.0039, 0.0039, 0.0078],\n",
      "          [0.2000, 0.1961, 0.2078,  ..., 0.0039, 0.0039, 0.0078]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.0627, 0.0471, 0.0235,  ..., 0.0353, 0.0392, 0.0392],\n",
      "          [0.0588, 0.0392, 0.0196,  ..., 0.0353, 0.0431, 0.0471],\n",
      "          [0.0588, 0.0431, 0.0196,  ..., 0.0392, 0.0471, 0.0510]]],\n",
      "\n",
      "\n",
      "        [[[0.8235, 0.8235, 0.8157,  ..., 0.1490, 0.1922, 0.2157],\n",
      "          [0.8039, 0.8078, 0.7882,  ..., 0.1490, 0.1922, 0.2196],\n",
      "          [0.7804, 0.7608, 0.7176,  ..., 0.1451, 0.1922, 0.2157],\n",
      "          ...,\n",
      "          [0.0431, 0.0549, 0.0627,  ..., 0.4392, 0.3882, 0.2039],\n",
      "          [0.0275, 0.0392, 0.0510,  ..., 0.4353, 0.4078, 0.2784],\n",
      "          [0.0118, 0.0196, 0.0353,  ..., 0.4314, 0.4078, 0.3176]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.4706, 0.4745, 0.4706,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.4706, 0.4745, 0.4745,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.4745, 0.4784, 0.4745,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1647, 0.1804, 0.1490,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.1333, 0.1725, 0.1765,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0980, 0.1647, 0.2196,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.8471, 0.8627, 0.8706,  ..., 0.4706, 0.4706, 0.4627],\n",
      "          [0.8157, 0.8314, 0.8471,  ..., 0.5059, 0.5216, 0.5294],\n",
      "          [0.7725, 0.7882, 0.8000,  ..., 0.5647, 0.6000, 0.6196],\n",
      "          ...,\n",
      "          [0.5176, 0.5176, 0.5176,  ..., 0.0549, 0.1176, 0.1333],\n",
      "          [0.5137, 0.5137, 0.5137,  ..., 0.1137, 0.1922, 0.1961],\n",
      "          [0.5255, 0.5255, 0.5255,  ..., 0.1765, 0.2196, 0.2275]]],\n",
      "\n",
      "\n",
      "        [[[0.4275, 0.4157, 0.4000,  ..., 0.7098, 0.7137, 0.7176],\n",
      "          [0.4275, 0.4157, 0.3961,  ..., 0.7137, 0.7216, 0.7216],\n",
      "          [0.4314, 0.4196, 0.4000,  ..., 0.7176, 0.7176, 0.7255],\n",
      "          ...,\n",
      "          [0.6000, 0.5765, 0.5412,  ..., 0.1529, 0.3882, 0.4235],\n",
      "          [0.5098, 0.4902, 0.4824,  ..., 0.2314, 0.4549, 0.2549],\n",
      "          [0.4941, 0.4863, 0.4784,  ..., 0.3216, 0.3569, 0.1765]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.0032, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.003160834312439\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.2902, 0.2627, 0.2392,  ..., 0.1098, 0.1098, 0.1059],\n",
      "          [0.2353, 0.2157, 0.2078,  ..., 0.1098, 0.1098, 0.1020],\n",
      "          [0.1961, 0.1882, 0.1882,  ..., 0.1098, 0.1098, 0.1059]]],\n",
      "\n",
      "\n",
      "        [[[0.8353, 0.8314, 0.8275,  ..., 0.2039, 0.2784, 0.4000],\n",
      "          [0.6863, 0.6863, 0.6784,  ..., 0.1961, 0.2745, 0.4118],\n",
      "          [0.3216, 0.3373, 0.3451,  ..., 0.1961, 0.2784, 0.4078],\n",
      "          ...,\n",
      "          [0.1020, 0.0980, 0.1020,  ..., 0.1098, 0.1059, 0.0863],\n",
      "          [0.1137, 0.0980, 0.1059,  ..., 0.1137, 0.1059, 0.0902],\n",
      "          [0.1176, 0.1020, 0.0980,  ..., 0.0980, 0.1098, 0.0980]]],\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0745, 0.0706, 0.0706,  ..., 0.0745, 0.0784, 0.0784],\n",
      "          ...,\n",
      "          [0.2078, 0.2235, 0.2392,  ..., 0.2235, 0.2235, 0.2235],\n",
      "          [0.2196, 0.2275, 0.2314,  ..., 0.2235, 0.2235, 0.2235],\n",
      "          [0.2235, 0.2235, 0.2196,  ..., 0.2314, 0.2196, 0.2235]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0510, 0.0627, 0.0627,  ..., 0.5333, 0.8510, 0.8745],\n",
      "          [0.0471, 0.0510, 0.0510,  ..., 0.2275, 0.6784, 0.8667],\n",
      "          [0.0510, 0.0392, 0.0431,  ..., 0.1765, 0.4000, 0.8000]]],\n",
      "\n",
      "\n",
      "        [[[0.0392, 0.0392, 0.0431,  ..., 0.0431, 0.0431, 0.0471],\n",
      "          [0.3961, 0.4078, 0.4118,  ..., 0.4353, 0.4471, 0.4510],\n",
      "          [0.5529, 0.5686, 0.5804,  ..., 0.6039, 0.6196, 0.6275],\n",
      "          ...,\n",
      "          [0.0471, 0.0627, 0.1059,  ..., 0.1490, 0.1608, 0.1686],\n",
      "          [0.0471, 0.0667, 0.1098,  ..., 0.1529, 0.1608, 0.1647],\n",
      "          [0.0510, 0.0745, 0.1137,  ..., 0.1529, 0.1608, 0.1412]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1961, 0.2078, 0.1882,  ..., 0.2196, 0.2353, 0.2510],\n",
      "          [0.1843, 0.2000, 0.2000,  ..., 0.2196, 0.2353, 0.2510],\n",
      "          [0.1765, 0.1843, 0.1922,  ..., 0.2196, 0.2353, 0.2510]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(0.9974, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 0.9973849654197693\n",
      "\n",
      "tensor([[[[0.8549, 0.8510, 0.8549,  ..., 0.8706, 0.8863, 0.8980],\n",
      "          [0.8588, 0.8549, 0.8588,  ..., 0.8588, 0.8745, 0.9098],\n",
      "          [0.8588, 0.8549, 0.8588,  ..., 0.8784, 0.8784, 0.9412],\n",
      "          ...,\n",
      "          [0.0627, 0.0667, 0.0706,  ..., 0.0275, 0.2471, 0.4118],\n",
      "          [0.0588, 0.0745, 0.0745,  ..., 0.0235, 0.2353, 0.4039],\n",
      "          [0.0549, 0.0784, 0.0745,  ..., 0.0196, 0.2196, 0.3961]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0667, 0.0667, 0.0627,  ..., 0.1059, 0.1059, 0.1059],\n",
      "          [0.0667, 0.0667, 0.0627,  ..., 0.1059, 0.1059, 0.1059],\n",
      "          [0.0627, 0.0667, 0.0627,  ..., 0.1137, 0.1137, 0.1098]]],\n",
      "\n",
      "\n",
      "        [[[0.6745, 0.6392, 0.6196,  ..., 0.6157, 0.6235, 0.6235],\n",
      "          [0.7020, 0.6706, 0.6353,  ..., 0.6196, 0.6275, 0.6275],\n",
      "          [0.7176, 0.7020, 0.6627,  ..., 0.6235, 0.6275, 0.6275],\n",
      "          ...,\n",
      "          [0.1804, 0.1098, 0.1255,  ..., 0.0667, 0.0863, 0.0863],\n",
      "          [0.0980, 0.1020, 0.1255,  ..., 0.0784, 0.0902, 0.0863],\n",
      "          [0.1059, 0.0941, 0.1098,  ..., 0.0824, 0.0863, 0.0824]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0980, 0.1059, 0.1098,  ..., 0.0745, 0.0706, 0.0627],\n",
      "          [0.0980, 0.0980, 0.1059,  ..., 0.0706, 0.0667, 0.0627],\n",
      "          [0.1059, 0.0941, 0.0980,  ..., 0.0627, 0.0706, 0.0667]]],\n",
      "\n",
      "\n",
      "        [[[0.4902, 0.5569, 0.6000,  ..., 0.3882, 0.3922, 0.3961],\n",
      "          [0.4941, 0.5725, 0.6118,  ..., 0.4000, 0.4000, 0.4039],\n",
      "          [0.4902, 0.5686, 0.6039,  ..., 0.4078, 0.4078, 0.4118],\n",
      "          ...,\n",
      "          [0.2706, 0.2275, 0.1882,  ..., 0.0863, 0.0902, 0.1020],\n",
      "          [0.2314, 0.1922, 0.1725,  ..., 0.1059, 0.1020, 0.1137],\n",
      "          [0.2000, 0.2000, 0.1882,  ..., 0.1098, 0.1255, 0.1255]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1333, 0.1216, 0.0863,  ..., 0.2431, 0.2510, 0.2627],\n",
      "          [0.1255, 0.1216, 0.0902,  ..., 0.2431, 0.2471, 0.2549],\n",
      "          [0.1216, 0.1216, 0.0941,  ..., 0.2471, 0.2588, 0.2627]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.1459, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.1458940505981445\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.3059, 0.3922, 0.4235,  ..., 0.1176, 0.1255, 0.1216],\n",
      "          [0.2745, 0.3569, 0.4000,  ..., 0.1098, 0.1216, 0.1294],\n",
      "          [0.2510, 0.3333, 0.3882,  ..., 0.1059, 0.1255, 0.1333]]],\n",
      "\n",
      "\n",
      "        [[[0.8863, 0.8667, 0.8314,  ..., 0.1059, 0.1255, 0.1294],\n",
      "          [0.8863, 0.8706, 0.8314,  ..., 0.1255, 0.1333, 0.1294],\n",
      "          [0.8902, 0.8667, 0.8314,  ..., 0.1490, 0.1490, 0.1412],\n",
      "          ...,\n",
      "          [0.2745, 0.2745, 0.2980,  ..., 0.0196, 0.0667, 0.0980],\n",
      "          [0.2706, 0.2784, 0.2824,  ..., 0.0275, 0.0706, 0.0980],\n",
      "          [0.2745, 0.2902, 0.3020,  ..., 0.0314, 0.0706, 0.0980]]],\n",
      "\n",
      "\n",
      "        [[[0.5804, 0.5765, 0.5804,  ..., 0.5922, 0.5686, 0.5922],\n",
      "          [0.5961, 0.5882, 0.5804,  ..., 0.6000, 0.5647, 0.5882],\n",
      "          [0.6039, 0.5961, 0.5882,  ..., 0.6000, 0.5686, 0.5882],\n",
      "          ...,\n",
      "          [0.1373, 0.1294, 0.1294,  ..., 0.1922, 0.1804, 0.1647],\n",
      "          [0.1294, 0.1255, 0.1255,  ..., 0.1765, 0.1608, 0.1412],\n",
      "          [0.1373, 0.1294, 0.1255,  ..., 0.1647, 0.1569, 0.1412]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.1333, 0.1333, 0.1294,  ..., 0.0431, 0.0431, 0.0431],\n",
      "          [0.6745, 0.6667, 0.6627,  ..., 0.1686, 0.1686, 0.1686],\n",
      "          [0.7804, 0.7686, 0.7686,  ..., 0.1961, 0.1961, 0.1961],\n",
      "          ...,\n",
      "          [0.7725, 0.7373, 0.6941,  ..., 0.1804, 0.1686, 0.1412],\n",
      "          [0.7647, 0.7176, 0.6824,  ..., 0.1843, 0.1608, 0.1373],\n",
      "          [0.7451, 0.7098, 0.6980,  ..., 0.1882, 0.1569, 0.1373]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.2039, 0.2078, 0.2078,  ..., 0.1922, 0.1843, 0.2824],\n",
      "          [0.2039, 0.2039, 0.2039,  ..., 0.1922, 0.1804, 0.2392],\n",
      "          [0.2039, 0.2039, 0.2000,  ..., 0.1961, 0.1882, 0.2353]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.3294, 0.6745, 0.6431],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1686, 0.6078, 0.7725],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0902, 0.4627, 0.7451]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.1982, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.1981500387191772\n",
      "\n",
      "tensor([[[[0.8392, 0.8431, 0.8196,  ..., 0.8510, 0.8471, 0.8431],\n",
      "          [0.8275, 0.8353, 0.8157,  ..., 0.8627, 0.8588, 0.8510],\n",
      "          [0.8157, 0.8235, 0.8118,  ..., 0.8549, 0.8588, 0.8510],\n",
      "          ...,\n",
      "          [0.5529, 0.5490, 0.5373,  ..., 0.8157, 0.8118, 0.8039],\n",
      "          [0.5529, 0.5490, 0.5333,  ..., 0.8157, 0.8078, 0.8000],\n",
      "          [0.5451, 0.5373, 0.5333,  ..., 0.8118, 0.8039, 0.8000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1176, 0.0863, 0.1333,  ..., 0.2118, 0.1882, 0.1529],\n",
      "          [0.1412, 0.0824, 0.1216,  ..., 0.1608, 0.1216, 0.1137],\n",
      "          [0.1451, 0.0784, 0.1137,  ..., 0.1176, 0.1294, 0.1647]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.8706, 0.8392, 0.7922,  ..., 0.1765, 0.1451, 0.1412],\n",
      "          [0.8510, 0.8353, 0.7843,  ..., 0.1569, 0.1529, 0.1490],\n",
      "          [0.8118, 0.8078, 0.7725,  ..., 0.1412, 0.1529, 0.1686]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.3137, 0.3098, 0.3059],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.3176, 0.3176, 0.3137],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.3255, 0.3294, 0.3294],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1137, 0.1490, 0.1137],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1059, 0.1451, 0.1176],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0980, 0.1333, 0.1137]]],\n",
      "\n",
      "\n",
      "        [[[1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          [1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
      "          ...,\n",
      "          [0.0275, 0.0353, 0.0510,  ..., 0.1333, 0.1255, 0.1216],\n",
      "          [0.0353, 0.0431, 0.0549,  ..., 0.1255, 0.1294, 0.1216],\n",
      "          [0.0353, 0.0471, 0.0510,  ..., 0.1216, 0.1176, 0.1255]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0196, 0.0196, 0.0196],\n",
      "          ...,\n",
      "          [0.0275, 0.0275, 0.0275,  ..., 0.6157, 0.5843, 0.6196],\n",
      "          [0.0157, 0.0196, 0.0196,  ..., 0.7137, 0.6784, 0.6627],\n",
      "          [0.0196, 0.0196, 0.0157,  ..., 0.7451, 0.7059, 0.6863]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.1148, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.1148463487625122\n",
      "\n",
      "tensor([[[[0.0039, 0.0039, 0.0039,  ..., 0.0000, 0.0039, 0.0039],\n",
      "          [0.0157, 0.0157, 0.0196,  ..., 0.0275, 0.0314, 0.0314],\n",
      "          [0.1333, 0.1451, 0.2118,  ..., 0.4000, 0.4235, 0.4431],\n",
      "          ...,\n",
      "          [0.1412, 0.1529, 0.1804,  ..., 0.1098, 0.1059, 0.1059],\n",
      "          [0.1333, 0.1451, 0.1882,  ..., 0.1098, 0.1137, 0.1098],\n",
      "          [0.1294, 0.1451, 0.1922,  ..., 0.1137, 0.1137, 0.1098]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.2980, 0.3098, 0.3098,  ..., 0.6275, 0.6235, 0.6157],\n",
      "          [0.2784, 0.3020, 0.3176,  ..., 0.6353, 0.6275, 0.6078],\n",
      "          [0.2314, 0.2588, 0.2863,  ..., 0.6314, 0.6275, 0.6157]]],\n",
      "\n",
      "\n",
      "        [[[0.1569, 0.1098, 0.1020,  ..., 0.0431, 0.0392, 0.0353],\n",
      "          [0.1608, 0.1412, 0.1333,  ..., 0.0392, 0.0314, 0.0275],\n",
      "          [0.1569, 0.1529, 0.1608,  ..., 0.0314, 0.0353, 0.0275],\n",
      "          ...,\n",
      "          [0.0118, 0.0118, 0.0235,  ..., 0.0314, 0.0353, 0.0314],\n",
      "          [0.0078, 0.0118, 0.0196,  ..., 0.0275, 0.0314, 0.0314],\n",
      "          [0.0157, 0.0157, 0.0196,  ..., 0.0275, 0.0275, 0.0314]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0471, 0.0510, 0.0588,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0392, 0.0431, 0.0510,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0431, 0.0431, 0.0431,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.9882, 0.9922, 0.9843,  ..., 0.9804, 0.9804, 0.9608],\n",
      "          [0.9882, 0.9882, 0.9804,  ..., 0.9804, 0.9843, 0.9686],\n",
      "          [0.9922, 0.9922, 0.9804,  ..., 0.9843, 0.9843, 0.9725],\n",
      "          ...,\n",
      "          [0.0353, 0.0353, 0.0353,  ..., 0.0039, 0.0078, 0.0039],\n",
      "          [0.0314, 0.0314, 0.0353,  ..., 0.0118, 0.0118, 0.0118],\n",
      "          [0.0235, 0.0275, 0.0392,  ..., 0.0078, 0.0118, 0.0157]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0196, 0.0196, 0.0196],\n",
      "          ...,\n",
      "          [0.0275, 0.0275, 0.0275,  ..., 0.6157, 0.5843, 0.6196],\n",
      "          [0.0157, 0.0196, 0.0196,  ..., 0.7137, 0.6784, 0.6627],\n",
      "          [0.0196, 0.0196, 0.0157,  ..., 0.7451, 0.7059, 0.6863]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.3414, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.3414148092269897\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0196, 0.0235, 0.0275,  ..., 0.0235, 0.0392, 0.0549],\n",
      "          ...,\n",
      "          [0.1137, 0.1098, 0.0980,  ..., 0.2000, 0.4706, 0.6353],\n",
      "          [0.1020, 0.1098, 0.0980,  ..., 0.2157, 0.4706, 0.5961],\n",
      "          [0.0980, 0.1137, 0.1020,  ..., 0.2039, 0.4235, 0.5373]]],\n",
      "\n",
      "\n",
      "        [[[0.5686, 0.5647, 0.5529,  ..., 0.8863, 0.9020, 0.9020],\n",
      "          [0.5608, 0.5686, 0.5765,  ..., 0.8784, 0.8902, 0.8863],\n",
      "          [0.5686, 0.5725, 0.5961,  ..., 0.8353, 0.7529, 0.6549],\n",
      "          ...,\n",
      "          [0.0627, 0.0706, 0.0745,  ..., 0.1020, 0.1137, 0.1176],\n",
      "          [0.0667, 0.0706, 0.0745,  ..., 0.0980, 0.1059, 0.1137],\n",
      "          [0.0667, 0.0706, 0.0745,  ..., 0.0941, 0.0941, 0.0980]]],\n",
      "\n",
      "\n",
      "        [[[0.3647, 0.3412, 0.3098,  ..., 0.0157, 0.0039, 0.0039],\n",
      "          [0.3176, 0.2863, 0.2588,  ..., 0.0157, 0.0039, 0.0039],\n",
      "          [0.2549, 0.2392, 0.2275,  ..., 0.0157, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.3490, 0.3686, 0.3882,  ..., 0.0039, 0.0000, 0.0000],\n",
      "          [0.3098, 0.3255, 0.3451,  ..., 0.0039, 0.0000, 0.0000],\n",
      "          [0.3882, 0.4078, 0.4235,  ..., 0.0039, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.4118, 0.4039, 0.4039],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.4118, 0.4314, 0.4235],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.4353, 0.4588, 0.4431]]],\n",
      "\n",
      "\n",
      "        [[[0.0078, 0.0039, 0.0039,  ..., 0.4627, 0.4588, 0.4627],\n",
      "          [0.0039, 0.0000, 0.0000,  ..., 0.4667, 0.4627, 0.4667],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.4706, 0.4667, 0.4706],\n",
      "          ...,\n",
      "          [0.0078, 0.0078, 0.0000,  ..., 0.0392, 0.0353, 0.0392],\n",
      "          [0.0078, 0.0078, 0.0039,  ..., 0.0353, 0.0314, 0.0392],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0353, 0.0314, 0.0314]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0000],\n",
      "          [0.4667, 0.4667, 0.4667,  ..., 0.4627, 0.4627, 0.4588],\n",
      "          ...,\n",
      "          [0.1882, 0.1843, 0.1725,  ..., 0.1647, 0.1882, 0.1961],\n",
      "          [0.1843, 0.1804, 0.1804,  ..., 0.1725, 0.1843, 0.1843],\n",
      "          [0.1804, 0.1765, 0.1804,  ..., 0.1765, 0.1765, 0.1725]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(0.8461, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 0.8460531830787659\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1843, 0.1843, 0.1882,  ..., 0.1451, 0.1451, 0.1451],\n",
      "          [0.1882, 0.1882, 0.1922,  ..., 0.1490, 0.1529, 0.1490],\n",
      "          [0.1882, 0.1882, 0.1922,  ..., 0.1529, 0.1569, 0.1490]]],\n",
      "\n",
      "\n",
      "        [[[0.0157, 0.0157, 0.0196,  ..., 0.0118, 0.0118, 0.0118],\n",
      "          [0.0157, 0.0196, 0.0275,  ..., 0.0157, 0.0078, 0.0039],\n",
      "          [0.0157, 0.0235, 0.0275,  ..., 0.0118, 0.0078, 0.0000],\n",
      "          ...,\n",
      "          [0.0667, 0.0549, 0.0431,  ..., 0.0431, 0.0353, 0.0431],\n",
      "          [0.0588, 0.0627, 0.0627,  ..., 0.0392, 0.0314, 0.0471],\n",
      "          [0.0667, 0.0745, 0.0784,  ..., 0.0471, 0.0353, 0.0588]]],\n",
      "\n",
      "\n",
      "        [[[0.0549, 0.0510, 0.2196,  ..., 0.0549, 0.0549, 0.0510],\n",
      "          [0.0392, 0.0667, 0.2392,  ..., 0.0549, 0.0510, 0.0392],\n",
      "          [0.0431, 0.0745, 0.2549,  ..., 0.0431, 0.0392, 0.0314],\n",
      "          ...,\n",
      "          [0.1647, 0.3333, 0.3843,  ..., 0.2118, 0.2039, 0.2000],\n",
      "          [0.3020, 0.6275, 0.6510,  ..., 0.2157, 0.2078, 0.2039],\n",
      "          [0.3961, 0.7451, 0.7608,  ..., 0.2196, 0.2157, 0.2078]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.1608, 0.1176, 0.1608,  ..., 0.1490, 0.1137, 0.0745],\n",
      "          [0.1333, 0.1176, 0.1647,  ..., 0.1333, 0.0941, 0.0549],\n",
      "          [0.1137, 0.1176, 0.1647,  ..., 0.1098, 0.0706, 0.0431],\n",
      "          ...,\n",
      "          [0.3922, 0.3922, 0.3961,  ..., 0.4784, 0.5020, 0.5216],\n",
      "          [0.3804, 0.3843, 0.3882,  ..., 0.5059, 0.5059, 0.5098],\n",
      "          [0.3725, 0.3804, 0.3843,  ..., 0.5020, 0.4863, 0.4627]]],\n",
      "\n",
      "\n",
      "        [[[0.8118, 0.8118, 0.8118,  ..., 0.2745, 0.2784, 0.2824],\n",
      "          [0.8157, 0.8157, 0.8157,  ..., 0.2353, 0.2275, 0.2314],\n",
      "          [0.8196, 0.8196, 0.8078,  ..., 0.2392, 0.2431, 0.2353],\n",
      "          ...,\n",
      "          [0.3922, 0.3961, 0.3882,  ..., 0.1176, 0.1137, 0.1255],\n",
      "          [0.3529, 0.4000, 0.4314,  ..., 0.1137, 0.1020, 0.1098],\n",
      "          [0.2745, 0.3255, 0.3882,  ..., 0.1137, 0.0980, 0.0941]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0039,  ..., 0.4824, 0.6078, 0.7294],\n",
      "          [0.0000, 0.0000, 0.0039,  ..., 0.3843, 0.4902, 0.6431],\n",
      "          [0.0000, 0.0000, 0.0039,  ..., 0.3333, 0.4078, 0.5176],\n",
      "          ...,\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.7725, 0.7725, 0.8157],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.7686, 0.7843, 0.8157],\n",
      "          [0.0000, 0.0000, 0.0039,  ..., 0.7686, 0.7882, 0.8196]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.1752, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.1752368211746216\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.4471, 0.2235, 0.1686,  ..., 0.0353, 0.0392, 0.0392],\n",
      "          [0.4667, 0.2392, 0.1765,  ..., 0.0353, 0.0392, 0.0392],\n",
      "          [0.4745, 0.2392, 0.1843,  ..., 0.0314, 0.0353, 0.0392]]],\n",
      "\n",
      "\n",
      "        [[[0.0980, 0.0392, 0.0275,  ..., 0.0745, 0.0706, 0.0667],\n",
      "          [0.1059, 0.0471, 0.0314,  ..., 0.0824, 0.0706, 0.0667],\n",
      "          [0.1176, 0.0549, 0.0353,  ..., 0.0824, 0.0784, 0.0745],\n",
      "          ...,\n",
      "          [0.1020, 0.1176, 0.1255,  ..., 0.1098, 0.0706, 0.0392],\n",
      "          [0.1020, 0.1216, 0.1137,  ..., 0.0706, 0.0353, 0.0118],\n",
      "          [0.1216, 0.1176, 0.1137,  ..., 0.0431, 0.0157, 0.0078]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.5608, 0.3412, 0.1804,  ..., 0.1686, 0.1608, 0.1569],\n",
      "          [0.4235, 0.2549, 0.2039,  ..., 0.1647, 0.1608, 0.1647],\n",
      "          [0.2392, 0.2039, 0.1961,  ..., 0.1569, 0.1569, 0.1569]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1961, 0.2078, 0.1882,  ..., 0.2196, 0.2353, 0.2510],\n",
      "          [0.1843, 0.2000, 0.2000,  ..., 0.2196, 0.2353, 0.2510],\n",
      "          [0.1765, 0.1843, 0.1922,  ..., 0.2196, 0.2353, 0.2510]]],\n",
      "\n",
      "\n",
      "        [[[0.7686, 0.8196, 0.8314,  ..., 0.7059, 0.4157, 0.2745],\n",
      "          [0.8039, 0.8314, 0.8314,  ..., 0.6980, 0.4078, 0.2667],\n",
      "          [0.8235, 0.8196, 0.7765,  ..., 0.6941, 0.3961, 0.2706],\n",
      "          ...,\n",
      "          [0.0824, 0.1020, 0.1059,  ..., 0.1843, 0.2118, 0.2392],\n",
      "          [0.0745, 0.1255, 0.1255,  ..., 0.1804, 0.2039, 0.2314],\n",
      "          [0.0980, 0.1216, 0.1216,  ..., 0.1804, 0.2078, 0.2353]]],\n",
      "\n",
      "\n",
      "        [[[0.9020, 0.9255, 0.9333,  ..., 0.2078, 0.2039, 0.2118],\n",
      "          [0.9020, 0.9255, 0.9333,  ..., 0.2235, 0.2039, 0.2078],\n",
      "          [0.9020, 0.9255, 0.9333,  ..., 0.2549, 0.2353, 0.2275],\n",
      "          ...,\n",
      "          [0.2039, 0.1961, 0.2078,  ..., 0.2627, 0.2980, 0.3255],\n",
      "          [0.2039, 0.2078, 0.2157,  ..., 0.2549, 0.3020, 0.3294],\n",
      "          [0.2078, 0.2000, 0.2078,  ..., 0.2549, 0.3059, 0.3333]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.0469, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.046934962272644\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.3059, 0.2157, 0.0863,  ..., 0.1843, 0.2510, 0.2667],\n",
      "          [0.2706, 0.1412, 0.0824,  ..., 0.2627, 0.2078, 0.1647],\n",
      "          [0.2039, 0.1020, 0.0941,  ..., 0.1765, 0.1804, 0.2078]]],\n",
      "\n",
      "\n",
      "        [[[0.9804, 0.9922, 0.9882,  ..., 0.1843, 0.2275, 0.2667],\n",
      "          [0.9843, 0.9882, 0.9843,  ..., 0.1686, 0.2118, 0.2510],\n",
      "          [0.9765, 0.9804, 0.9804,  ..., 0.1529, 0.1922, 0.2314],\n",
      "          ...,\n",
      "          [0.0667, 0.0667, 0.0588,  ..., 0.3176, 0.2863, 0.2471],\n",
      "          [0.0667, 0.0667, 0.0588,  ..., 0.3608, 0.3333, 0.2941],\n",
      "          [0.0667, 0.0667, 0.0627,  ..., 0.4078, 0.3843, 0.3490]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0784, 0.1020, 0.1373,  ..., 0.2196, 0.2196, 0.2078],\n",
      "          [0.1255, 0.1098, 0.1451,  ..., 0.2196, 0.2118, 0.2118],\n",
      "          [0.1647, 0.1490, 0.1686,  ..., 0.2078, 0.2078, 0.2078]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.7451, 0.8824, 0.9725,  ..., 0.9882, 0.9882, 0.9882],\n",
      "          [0.7373, 0.7451, 0.8745,  ..., 0.9882, 0.9882, 0.9882],\n",
      "          [0.6980, 0.6941, 0.7098,  ..., 0.9882, 0.9882, 0.9882],\n",
      "          ...,\n",
      "          [0.6000, 0.5882, 0.6078,  ..., 0.2039, 0.2471, 0.2941],\n",
      "          [0.5843, 0.5922, 0.6078,  ..., 0.2275, 0.2471, 0.2667],\n",
      "          [0.5725, 0.5765, 0.5922,  ..., 0.2275, 0.2431, 0.2235]]],\n",
      "\n",
      "\n",
      "        [[[0.0431, 0.0392, 0.0471,  ..., 0.0627, 0.0824, 0.0980],\n",
      "          [0.0510, 0.0471, 0.0471,  ..., 0.0510, 0.0706, 0.0863],\n",
      "          [0.0510, 0.0510, 0.0549,  ..., 0.0588, 0.0627, 0.0706],\n",
      "          ...,\n",
      "          [0.1020, 0.0902, 0.1137,  ..., 0.6667, 0.6392, 0.6627],\n",
      "          [0.0941, 0.0902, 0.1098,  ..., 0.6196, 0.6235, 0.5412],\n",
      "          [0.1020, 0.1059, 0.1137,  ..., 0.5137, 0.5725, 0.5490]]],\n",
      "\n",
      "\n",
      "        [[[0.1412, 0.1373, 0.1373,  ..., 0.2941, 0.5137, 0.6510],\n",
      "          [0.1451, 0.1373, 0.1373,  ..., 0.2431, 0.4392, 0.6196],\n",
      "          [0.1451, 0.1373, 0.1373,  ..., 0.2000, 0.3569, 0.5529],\n",
      "          ...,\n",
      "          [0.2314, 0.2471, 0.2549,  ..., 0.0549, 0.0706, 0.0745],\n",
      "          [0.2078, 0.2196, 0.2196,  ..., 0.0667, 0.0667, 0.0627],\n",
      "          [0.1922, 0.2000, 0.1961,  ..., 0.0706, 0.0667, 0.0549]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.1427, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.1427432298660278\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.5765, 0.5569, 0.5451,  ..., 0.3569, 0.3412, 0.3176],\n",
      "          [0.5490, 0.5529, 0.6078,  ..., 0.4902, 0.4314, 0.4353],\n",
      "          [0.5412, 0.6431, 0.8275,  ..., 0.7922, 0.6588, 0.5373]]],\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0039, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0784, 0.0588, 0.0627,  ..., 0.1686, 0.1686, 0.1608],\n",
      "          [0.0706, 0.0706, 0.0706,  ..., 0.1725, 0.1608, 0.1569],\n",
      "          [0.0941, 0.0863, 0.0745,  ..., 0.1686, 0.1608, 0.1569]]],\n",
      "\n",
      "\n",
      "        [[[0.6824, 0.7137, 0.6980,  ..., 0.6000, 0.6706, 0.6824],\n",
      "          [0.7725, 0.7765, 0.7490,  ..., 0.5882, 0.6510, 0.6824],\n",
      "          [0.8157, 0.8118, 0.7922,  ..., 0.6353, 0.6627, 0.6863],\n",
      "          ...,\n",
      "          [0.8196, 0.6980, 0.6784,  ..., 0.5725, 0.5608, 0.5333],\n",
      "          [0.7569, 0.7765, 0.7961,  ..., 0.5529, 0.5490, 0.5412],\n",
      "          [0.6353, 0.6745, 0.7020,  ..., 0.5569, 0.5294, 0.5373]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.9373, 0.9373, 0.9373,  ..., 0.4667, 0.4667, 0.4667],\n",
      "          [0.9373, 0.9373, 0.9373,  ..., 0.4118, 0.4157, 0.4196],\n",
      "          [0.9373, 0.9373, 0.9373,  ..., 0.3686, 0.3765, 0.3804],\n",
      "          ...,\n",
      "          [0.1059, 0.1098, 0.1216,  ..., 0.5725, 0.3412, 0.1569],\n",
      "          [0.1020, 0.1098, 0.1176,  ..., 0.8549, 0.6980, 0.3608],\n",
      "          [0.1020, 0.1098, 0.1176,  ..., 0.7373, 0.7529, 0.5020]]],\n",
      "\n",
      "\n",
      "        [[[0.2196, 0.2314, 0.2667,  ..., 0.2353, 0.2471, 0.2588],\n",
      "          [0.1725, 0.1882, 0.2235,  ..., 0.2824, 0.3098, 0.3333],\n",
      "          [0.1647, 0.1843, 0.2275,  ..., 0.3294, 0.3765, 0.4118],\n",
      "          ...,\n",
      "          [0.4000, 0.3843, 0.3647,  ..., 0.3882, 0.3608, 0.3216],\n",
      "          [0.3843, 0.3569, 0.3255,  ..., 0.4039, 0.3882, 0.3490],\n",
      "          [0.3569, 0.3255, 0.3098,  ..., 0.4196, 0.4078, 0.3686]]],\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0000, 0.0039],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0039, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.1451, 0.1569, 0.1843,  ..., 0.1137, 0.1569, 0.1608],\n",
      "          [0.1569, 0.1765, 0.1843,  ..., 0.0941, 0.1098, 0.1373],\n",
      "          [0.1686, 0.1804, 0.1765,  ..., 0.0941, 0.0863, 0.1098]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.3451, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.3451205492019653\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.4431, 0.4510, 0.4510],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.4392, 0.4471, 0.4510],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.4392, 0.4549, 0.4549],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1255, 0.1216, 0.1216],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1255, 0.1137, 0.1059],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1216, 0.1059, 0.1059]]],\n",
      "\n",
      "\n",
      "        [[[0.0235, 0.0196, 0.0196,  ..., 0.0392, 0.0706, 0.1451],\n",
      "          [0.0235, 0.0235, 0.0235,  ..., 0.0471, 0.0706, 0.1373],\n",
      "          [0.0235, 0.0314, 0.0275,  ..., 0.0431, 0.0627, 0.1216],\n",
      "          ...,\n",
      "          [0.5451, 0.2824, 0.2471,  ..., 0.1098, 0.1216, 0.1255],\n",
      "          [0.6588, 0.4824, 0.2627,  ..., 0.1098, 0.1216, 0.1255],\n",
      "          [0.6667, 0.6039, 0.4000,  ..., 0.1216, 0.1294, 0.1255]]],\n",
      "\n",
      "\n",
      "        [[[0.3608, 0.3882, 0.4353,  ..., 0.3137, 0.3098, 0.3059],\n",
      "          [0.3608, 0.3765, 0.4235,  ..., 0.3137, 0.3098, 0.3059],\n",
      "          [0.3569, 0.3569, 0.4078,  ..., 0.3137, 0.3098, 0.3059],\n",
      "          ...,\n",
      "          [0.1843, 0.1843, 0.2000,  ..., 0.1451, 0.0941, 0.0902],\n",
      "          [0.1804, 0.1961, 0.1961,  ..., 0.1255, 0.0863, 0.0980],\n",
      "          [0.1843, 0.1882, 0.1922,  ..., 0.1059, 0.0902, 0.1020]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.8588, 0.8235, 0.8667,  ..., 0.9412, 0.8941, 0.8549],\n",
      "          [0.8588, 0.8235, 0.8667,  ..., 0.9412, 0.8941, 0.8549],\n",
      "          [0.8588, 0.8235, 0.8667,  ..., 0.9412, 0.8941, 0.8549],\n",
      "          ...,\n",
      "          [0.1412, 0.1451, 0.1490,  ..., 0.1333, 0.1255, 0.1176],\n",
      "          [0.1294, 0.1373, 0.1451,  ..., 0.1255, 0.1216, 0.1176],\n",
      "          [0.1255, 0.1373, 0.1490,  ..., 0.1255, 0.1255, 0.1176]]],\n",
      "\n",
      "\n",
      "        [[[0.0510, 0.0510, 0.0510,  ..., 0.0941, 0.1020, 0.1059],\n",
      "          [0.0824, 0.0824, 0.0824,  ..., 0.1529, 0.1647, 0.1725],\n",
      "          [0.0824, 0.0824, 0.0824,  ..., 0.1529, 0.1647, 0.1686],\n",
      "          ...,\n",
      "          [0.0902, 0.0863, 0.0902,  ..., 0.0706, 0.0471, 0.0314],\n",
      "          [0.0902, 0.0863, 0.0902,  ..., 0.0353, 0.0392, 0.0510],\n",
      "          [0.0941, 0.0941, 0.0941,  ..., 0.0588, 0.0745, 0.0863]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1490, 0.1451, 0.1373,  ..., 0.3529, 0.2706, 0.2039],\n",
      "          [0.1490, 0.1451, 0.1333,  ..., 0.3608, 0.3529, 0.2588],\n",
      "          [0.1412, 0.1412, 0.1412,  ..., 0.3451, 0.3686, 0.3529]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(0.8754, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 0.8754284977912903\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0118, 0.0275, 0.0275,  ..., 0.0078, 0.0039, 0.0039],\n",
      "          [0.0431, 0.0863, 0.0902,  ..., 0.0039, 0.0039, 0.0000],\n",
      "          [0.0471, 0.0902, 0.0980,  ..., 0.0039, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0745, 0.1255, 0.1373,  ..., 0.0039, 0.0000, 0.0000],\n",
      "          [0.0706, 0.1216, 0.1294,  ..., 0.0039, 0.0000, 0.0000],\n",
      "          [0.0627, 0.1137, 0.1216,  ..., 0.0000, 0.0039, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.4235, 0.4706, 0.5412,  ..., 0.7686, 0.7765, 0.7804],\n",
      "          [0.4275, 0.4784, 0.5451,  ..., 0.7686, 0.7765, 0.7804],\n",
      "          [0.4392, 0.4824, 0.5490,  ..., 0.7686, 0.7765, 0.7804],\n",
      "          ...,\n",
      "          [0.6588, 0.7608, 0.7922,  ..., 0.2157, 0.1843, 0.1412],\n",
      "          [0.7412, 0.7922, 0.8431,  ..., 0.2118, 0.1765, 0.1294],\n",
      "          [0.8431, 0.8471, 0.8196,  ..., 0.2118, 0.1647, 0.1255]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1333, 0.1373, 0.1294,  ..., 0.6941, 0.7216, 0.7137],\n",
      "          [0.1294, 0.1294, 0.1412,  ..., 0.6824, 0.8235, 0.8118],\n",
      "          [0.1294, 0.1255, 0.1255,  ..., 0.5882, 0.8510, 0.8471]]],\n",
      "\n",
      "\n",
      "        [[[0.7765, 0.7765, 0.7843,  ..., 0.5255, 0.5333, 0.5412],\n",
      "          [0.7765, 0.7843, 0.7922,  ..., 0.5412, 0.5490, 0.5569],\n",
      "          [0.7843, 0.7922, 0.8039,  ..., 0.5451, 0.5490, 0.5608],\n",
      "          ...,\n",
      "          [0.0902, 0.0824, 0.0784,  ..., 0.1098, 0.1059, 0.1020],\n",
      "          [0.0902, 0.0824, 0.0745,  ..., 0.1098, 0.1059, 0.1020],\n",
      "          [0.0824, 0.0784, 0.0784,  ..., 0.1059, 0.1059, 0.1059]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.2039, 0.2078, 0.2078,  ..., 0.1922, 0.1843, 0.2824],\n",
      "          [0.2039, 0.2039, 0.2039,  ..., 0.1922, 0.1804, 0.2392],\n",
      "          [0.2039, 0.2039, 0.2000,  ..., 0.1961, 0.1882, 0.2353]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.1524, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.1523891687393188\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0588, 0.0588, 0.0627,  ..., 0.3176, 0.2863, 0.2980],\n",
      "          [0.0549, 0.0588, 0.0588,  ..., 0.3216, 0.2784, 0.2824],\n",
      "          [0.0510, 0.0549, 0.0588,  ..., 0.3294, 0.2745, 0.2627]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0863, 0.0784, 0.0745,  ..., 0.1255, 0.1255, 0.1255],\n",
      "          [0.0784, 0.0863, 0.0902,  ..., 0.1216, 0.1255, 0.1137],\n",
      "          [0.0667, 0.0863, 0.1020,  ..., 0.1216, 0.1216, 0.1020]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0078, 0.0314,  ..., 0.2549, 0.2627, 0.2745],\n",
      "          [0.0000, 0.0078, 0.0314,  ..., 0.2588, 0.2706, 0.2863],\n",
      "          [0.0000, 0.0118, 0.0353,  ..., 0.2588, 0.2824, 0.2941]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.3725, 0.3765, 0.3686,  ..., 0.0039, 0.0000, 0.0000],\n",
      "          [0.3725, 0.3725, 0.3725,  ..., 0.0078, 0.0039, 0.0000],\n",
      "          [0.3686, 0.3725, 0.3725,  ..., 0.0039, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0824, 0.0745, 0.0627,  ..., 0.0627, 0.0667, 0.0667],\n",
      "          [0.0863, 0.0784, 0.0667,  ..., 0.0706, 0.0627, 0.0627],\n",
      "          [0.0863, 0.0824, 0.0667,  ..., 0.0627, 0.0706, 0.0745],\n",
      "          ...,\n",
      "          [0.2902, 0.2980, 0.3176,  ..., 0.1490, 0.1412, 0.1373],\n",
      "          [0.2863, 0.2941, 0.3098,  ..., 0.1176, 0.1098, 0.1059],\n",
      "          [0.2902, 0.2902, 0.3059,  ..., 0.0667, 0.0627, 0.0549]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1843, 0.1882, 0.1922,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.1804, 0.1882, 0.1843,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.1843, 0.1843, 0.1804,  ..., 0.0000, 0.0000, 0.0000]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.0991, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.0991324186325073\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.8510, 0.8627, 0.8667,  ..., 0.1333, 0.1373, 0.1333],\n",
      "          [0.8549, 0.8588, 0.8588,  ..., 0.1294, 0.1294, 0.1255],\n",
      "          [0.8588, 0.8588, 0.8549,  ..., 0.1255, 0.1255, 0.1216]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1569, 0.1333, 0.1098,  ..., 0.1725, 0.1843, 0.1725],\n",
      "          [0.1137, 0.1059, 0.1098,  ..., 0.1725, 0.1804, 0.1412],\n",
      "          [0.1059, 0.0980, 0.0941,  ..., 0.1882, 0.1686, 0.1490]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0196, 0.0196, 0.0196,  ..., 0.0196, 0.0196, 0.0196],\n",
      "          ...,\n",
      "          [0.2588, 0.2588, 0.2627,  ..., 0.1490, 0.1137, 0.0824],\n",
      "          [0.2471, 0.2588, 0.2627,  ..., 0.1216, 0.0863, 0.1020],\n",
      "          [0.2471, 0.2549, 0.2588,  ..., 0.1020, 0.0824, 0.1373]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0039, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1137, 0.1098, 0.1176,  ..., 0.1176, 0.1176, 0.1059],\n",
      "          [0.1176, 0.1098, 0.1098,  ..., 0.1137, 0.1098, 0.1020],\n",
      "          [0.1098, 0.1059, 0.1020,  ..., 0.1059, 0.1020, 0.1137]]],\n",
      "\n",
      "\n",
      "        [[[0.0902, 0.0745, 0.0667,  ..., 0.2314, 0.0314, 0.0000],\n",
      "          [0.1765, 0.1569, 0.1373,  ..., 0.4745, 0.0627, 0.0000],\n",
      "          [0.1765, 0.1569, 0.1373,  ..., 0.4824, 0.0627, 0.0039],\n",
      "          ...,\n",
      "          [0.1373, 0.1059, 0.0863,  ..., 0.2980, 0.0353, 0.0039],\n",
      "          [0.1451, 0.1412, 0.1176,  ..., 0.2824, 0.0353, 0.0039],\n",
      "          [0.1608, 0.1490, 0.1412,  ..., 0.2706, 0.0353, 0.0039]]],\n",
      "\n",
      "\n",
      "        [[[0.6039, 0.6275, 0.6510,  ..., 0.3804, 0.3882, 0.3843],\n",
      "          [0.6510, 0.6588, 0.6627,  ..., 0.3765, 0.3882, 0.3843],\n",
      "          [0.6941, 0.6863, 0.6784,  ..., 0.3765, 0.3843, 0.3843],\n",
      "          ...,\n",
      "          [0.0118, 0.0157, 0.0196,  ..., 0.0941, 0.0941, 0.0980],\n",
      "          [0.0078, 0.0157, 0.0196,  ..., 0.1059, 0.1020, 0.1020],\n",
      "          [0.0118, 0.0157, 0.0196,  ..., 0.1137, 0.1098, 0.1059]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.0358, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.0358060598373413\n",
      "\n",
      "tensor([[[[0.0078, 0.0196, 0.0510,  ..., 0.1176, 0.0941, 0.0157],\n",
      "          [0.0078, 0.0275, 0.0510,  ..., 0.1216, 0.1020, 0.0157],\n",
      "          [0.0078, 0.0353, 0.0549,  ..., 0.1255, 0.1137, 0.0196],\n",
      "          ...,\n",
      "          [0.1098, 0.1059, 0.1020,  ..., 0.1098, 0.0941, 0.0157],\n",
      "          [0.0941, 0.0902, 0.0941,  ..., 0.1137, 0.1020, 0.0157],\n",
      "          [0.0784, 0.0784, 0.0863,  ..., 0.1216, 0.1098, 0.0196]]],\n",
      "\n",
      "\n",
      "        [[[0.1647, 0.1725, 0.1725,  ..., 0.2431, 0.2431, 0.2431],\n",
      "          [0.1804, 0.1843, 0.1804,  ..., 0.2314, 0.2314, 0.2314],\n",
      "          [0.1961, 0.2000, 0.2078,  ..., 0.2392, 0.2392, 0.2431],\n",
      "          ...,\n",
      "          [0.0706, 0.0706, 0.0706,  ..., 0.1373, 0.1608, 0.1569],\n",
      "          [0.0706, 0.0706, 0.0706,  ..., 0.1373, 0.1490, 0.1529],\n",
      "          [0.0784, 0.0784, 0.0784,  ..., 0.1255, 0.1294, 0.1333]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0353, 0.4941, 0.7137,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0353, 0.4784, 0.6902,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0353, 0.4627, 0.6627,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0039, 0.0039,  ..., 0.0118, 0.0078, 0.0078],\n",
      "          [0.0196, 0.0157, 0.0157,  ..., 0.0510, 0.0510, 0.0471],\n",
      "          [0.0196, 0.0157, 0.0157,  ..., 0.0588, 0.0667, 0.0588],\n",
      "          ...,\n",
      "          [0.0157, 0.0157, 0.0392,  ..., 0.1020, 0.0941, 0.1059],\n",
      "          [0.0196, 0.0196, 0.0431,  ..., 0.0941, 0.0902, 0.0980],\n",
      "          [0.0157, 0.0157, 0.0353,  ..., 0.0863, 0.0980, 0.1059]]],\n",
      "\n",
      "\n",
      "        [[[0.9137, 0.9216, 0.9216,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9098, 0.9176, 0.9176,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9059, 0.9059, 0.9059,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0784, 0.0863, 0.1294,  ..., 0.4431, 0.5529, 0.5922],\n",
      "          [0.1373, 0.2353, 0.3412,  ..., 0.3255, 0.3804, 0.4549],\n",
      "          [0.3608, 0.4078, 0.3843,  ..., 0.3176, 0.3294, 0.3490]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.6784, 0.6667, 0.6549],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.6745, 0.6549, 0.6353],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.6588, 0.6314, 0.6078],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.8980, 0.9020, 0.9059],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.9059, 0.9098, 0.9137],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.9059, 0.9098, 0.9176]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.4378, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.4377937316894531\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0902, 0.1294, 0.1255,  ..., 0.0784, 0.0824, 0.0627],\n",
      "          [0.0745, 0.1137, 0.0863,  ..., 0.0784, 0.0588, 0.0588],\n",
      "          [0.0706, 0.0902, 0.0510,  ..., 0.0588, 0.0706, 0.0745]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0078, 0.0039, 0.0039],\n",
      "          [0.0039, 0.0000, 0.0039,  ..., 0.0078, 0.0039, 0.0000],\n",
      "          [0.1373, 0.1373, 0.1333,  ..., 0.0118, 0.0039, 0.0000],\n",
      "          ...,\n",
      "          [0.0471, 0.0863, 0.2941,  ..., 0.0118, 0.0039, 0.0000],\n",
      "          [0.1333, 0.2510, 0.3725,  ..., 0.0275, 0.0078, 0.0000],\n",
      "          [0.4157, 0.3451, 0.4314,  ..., 0.0196, 0.0039, 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.2431, 0.2471, 0.2392,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2706, 0.2824, 0.2667,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.2941, 0.2941, 0.2902,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0039, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0392, 0.0392, 0.0392,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0353, 0.0353, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0392, 0.0353, 0.0353,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.8588, 0.8235, 0.8667,  ..., 0.9412, 0.8941, 0.8549],\n",
      "          [0.8588, 0.8235, 0.8667,  ..., 0.9412, 0.8941, 0.8549],\n",
      "          [0.8588, 0.8235, 0.8667,  ..., 0.9412, 0.8941, 0.8549],\n",
      "          ...,\n",
      "          [0.1412, 0.1451, 0.1490,  ..., 0.1333, 0.1255, 0.1176],\n",
      "          [0.1294, 0.1373, 0.1451,  ..., 0.1255, 0.1216, 0.1176],\n",
      "          [0.1255, 0.1373, 0.1490,  ..., 0.1255, 0.1255, 0.1176]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.4458, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.4457961320877075\n",
      "\n",
      "tensor([[[[0.0000, 0.0000, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.6510, 0.7294, 0.7490,  ..., 0.1294, 0.1294, 0.1333],\n",
      "          [0.6235, 0.7176, 0.7451,  ..., 0.1333, 0.1333, 0.1333],\n",
      "          [0.6078, 0.7098, 0.7373,  ..., 0.1412, 0.1098, 0.0863]]],\n",
      "\n",
      "\n",
      "        [[[0.5765, 0.4980, 0.5216,  ..., 0.1608, 0.1686, 0.1922],\n",
      "          [0.6784, 0.5569, 0.5098,  ..., 0.1608, 0.1608, 0.1647],\n",
      "          [0.6157, 0.5333, 0.5059,  ..., 0.1529, 0.1490, 0.1569],\n",
      "          ...,\n",
      "          [0.0392, 0.0275, 0.0196,  ..., 0.0627, 0.0667, 0.0627],\n",
      "          [0.0392, 0.0275, 0.0157,  ..., 0.0627, 0.0627, 0.0588],\n",
      "          [0.0431, 0.0314, 0.0196,  ..., 0.0627, 0.0627, 0.0627]]],\n",
      "\n",
      "\n",
      "        [[[0.9216, 0.9255, 0.9333,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9216, 0.9255, 0.9333,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.9216, 0.9255, 0.9333,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0784, 0.0784, 0.0824,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0863, 0.0902, 0.0863,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0902, 0.0941, 0.0902,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0078, 0.0039],\n",
      "          [0.0510, 0.0431, 0.0431,  ..., 0.1216, 0.1490, 0.1804],\n",
      "          ...,\n",
      "          [0.3961, 0.4118, 0.4235,  ..., 0.0627, 0.0667, 0.0667],\n",
      "          [0.3569, 0.3725, 0.3922,  ..., 0.0627, 0.0667, 0.0706],\n",
      "          [0.3137, 0.3294, 0.3529,  ..., 0.0667, 0.0706, 0.0745]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.1922, 0.1843, 0.1882,  ..., 0.1804, 0.1647, 0.1529],\n",
      "          [0.1882, 0.1804, 0.1882,  ..., 0.1804, 0.1647, 0.1529],\n",
      "          [0.1843, 0.1843, 0.1922,  ..., 0.1804, 0.1529, 0.1490]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0039],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          ...,\n",
      "          [0.1020, 0.0941, 0.1098,  ..., 0.2000, 0.2000, 0.1804],\n",
      "          [0.0941, 0.0941, 0.1020,  ..., 0.1882, 0.1765, 0.1490],\n",
      "          [0.0863, 0.0902, 0.0980,  ..., 0.1725, 0.1529, 0.1216]]]]) torch.Size([24, 1, 100, 100])\n",
      "tensor(1.4979, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.4979192018508911\n",
      "\n",
      "tensor([[[[0.7843, 0.6627, 0.4824,  ..., 0.2039, 0.2314, 0.2549],\n",
      "          [0.5059, 0.3216, 0.2784,  ..., 0.2000, 0.2078, 0.2235],\n",
      "          [0.2392, 0.2667, 0.2941,  ..., 0.1882, 0.1843, 0.1922],\n",
      "          ...,\n",
      "          [0.2118, 0.1765, 0.1922,  ..., 0.1216, 0.1294, 0.1294],\n",
      "          [0.1647, 0.1961, 0.1647,  ..., 0.1255, 0.1294, 0.1294],\n",
      "          [0.1294, 0.1294, 0.1255,  ..., 0.1255, 0.1255, 0.1255]]],\n",
      "\n",
      "\n",
      "        [[[0.2784, 0.2745, 0.2706,  ..., 0.0196, 0.0196, 0.0196],\n",
      "          [0.2784, 0.2824, 0.2863,  ..., 0.0196, 0.0196, 0.0196],\n",
      "          [0.2784, 0.2824, 0.2824,  ..., 0.0196, 0.0196, 0.0196],\n",
      "          ...,\n",
      "          [0.2431, 0.2314, 0.2157,  ..., 0.1137, 0.1608, 0.1686],\n",
      "          [0.2392, 0.2275, 0.2157,  ..., 0.1216, 0.1961, 0.1922],\n",
      "          [0.2353, 0.2235, 0.2157,  ..., 0.1255, 0.1922, 0.1725]]],\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0039, 0.0039,  ..., 0.6078, 0.6157, 0.6471],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.6667, 0.6078, 0.5922],\n",
      "          [0.0039, 0.0000, 0.0039,  ..., 0.6157, 0.5569, 0.5059],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.2039, 0.1922, 0.1882],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1686, 0.1922, 0.1882],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.1451, 0.1882, 0.1765]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.3412, 0.3961, 0.4510,  ..., 0.1608, 0.1686, 0.1686],\n",
      "          [0.4235, 0.4824, 0.5373,  ..., 0.1647, 0.1686, 0.1686],\n",
      "          [0.4941, 0.5608, 0.6157,  ..., 0.1686, 0.1686, 0.1686],\n",
      "          ...,\n",
      "          [0.1176, 0.0941, 0.0510,  ..., 0.2980, 0.4431, 0.5608],\n",
      "          [0.1020, 0.1098, 0.0627,  ..., 0.3098, 0.4588, 0.5843],\n",
      "          [0.1098, 0.1020, 0.0863,  ..., 0.3255, 0.4745, 0.5765]]],\n",
      "\n",
      "\n",
      "        [[[0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0039, 0.0039, 0.0039,  ..., 0.0039, 0.0039, 0.0039],\n",
      "          [0.0745, 0.0706, 0.0706,  ..., 0.0745, 0.0784, 0.0784],\n",
      "          ...,\n",
      "          [0.2078, 0.2235, 0.2392,  ..., 0.2235, 0.2235, 0.2235],\n",
      "          [0.2196, 0.2275, 0.2314,  ..., 0.2235, 0.2235, 0.2235],\n",
      "          [0.2235, 0.2235, 0.2196,  ..., 0.2314, 0.2196, 0.2235]]],\n",
      "\n",
      "\n",
      "        [[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.4471, 0.2235, 0.1686,  ..., 0.0353, 0.0392, 0.0392],\n",
      "          [0.4667, 0.2392, 0.1765,  ..., 0.0353, 0.0392, 0.0392],\n",
      "          [0.4745, 0.2392, 0.1843,  ..., 0.0314, 0.0353, 0.0392]]]]) torch.Size([12, 1, 100, 100])\n",
      "tensor(1.3640, grad_fn=<MeanBackward0>)\n",
      "Epoch number 0\n",
      " Current loss 1.363961100578308\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "counter = []\n",
    "loss_history = []\n",
    "iteration_number= 0\n",
    "\n",
    "for i in range(1):\n",
    "  for j,(image1,image2,label) in enumerate(train_data_loader,0):\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    print(image1,image1.shape)\n",
    "    embedding1,embedding2 = Siamese_model(image1,image2)\n",
    "    loss = Contrasive_loss(embedding1,embedding2,label)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0 :\n",
    "            print(f\"Epoch number {i}\\n Current loss {loss.item()}\\n\")\n",
    "            iteration_number += 10\n",
    "\n",
    "            counter.append(iteration_number)\n",
    "            loss_history.append(loss.item())\n",
    "      \n",
    "show_plot(counter, loss_history)\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "54e51d0e-59a5-46a3-89b9-bbf3b5d6ab6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Could not run 'aten::empty_strided' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::empty_strided' is only available for these backends: [CPU, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterCPU.cpp:31034 [kernel]\nMeta: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterMeta.cpp:26824 [kernel]\nQuantizedCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterQuantizedCPU.cpp:929 [kernel]\nBackendSelect: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterBackendSelect.cpp:726 [kernel]\nPython: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:144 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:491 [backend fallback]\nFunctionalize: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:280 [backend fallback]\nNamed: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ConjugateFallback.cpp:21 [kernel]\nNegative: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\NegateFallback.cpp:23 [kernel]\nZeroTensor: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ZeroTensorFallback.cpp:90 [kernel]\nADInplaceOrView: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradOther: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradCUDA: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradHIP: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradXLA: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradMPS: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradIPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradXPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradHPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradVE: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradLazy: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradMeta: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradMTIA: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradPrivateUse1: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradPrivateUse2: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradPrivateUse3: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradNestedTensor: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nTracer: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\TraceType_2.cpp:16726 [kernel]\nAutocastCPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:487 [backend fallback]\nAutocastCUDA: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:354 [backend fallback]\nFuncTorchBatched: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:815 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1073 [backend fallback]\nVmapMode: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:152 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:487 [backend fallback]\nPythonDispatcher: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:148 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [61]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mSiamese_model(1).pt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Anaconda\\lib\\site-packages\\torch\\jit\\_serialization.py:162\u001b[0m, in \u001b[0;36mload\u001b[1;34m(f, map_location, _extra_files, _restore_shapes)\u001b[0m\n\u001b[0;32m    160\u001b[0m cu \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mCompilationUnit()\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPath)):\n\u001b[1;32m--> 162\u001b[0m     cpp_module \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_ir_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_extra_files\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_restore_shapes\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    164\u001b[0m     cpp_module \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39mimport_ir_module_from_buffer(\n\u001b[0;32m    165\u001b[0m         cu, f\u001b[38;5;241m.\u001b[39mread(), map_location, _extra_files, _restore_shapes\n\u001b[0;32m    166\u001b[0m     )  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n",
      "\u001b[1;31mNotImplementedError\u001b[0m: Could not run 'aten::empty_strided' with arguments from the 'CUDA' backend. This could be because the operator doesn't exist for this backend, or was omitted during the selective/custom build process (if using custom build). If you are a Facebook employee using PyTorch on mobile, please visit https://fburl.com/ptmfixes for possible resolutions. 'aten::empty_strided' is only available for these backends: [CPU, Meta, QuantizedCPU, BackendSelect, Python, FuncTorchDynamicLayerBackMode, Functionalize, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradHIP, AutogradXLA, AutogradMPS, AutogradIPU, AutogradXPU, AutogradHPU, AutogradVE, AutogradLazy, AutogradMeta, AutogradMTIA, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, AutogradNestedTensor, Tracer, AutocastCPU, AutocastCUDA, FuncTorchBatched, FuncTorchVmapMode, Batched, VmapMode, FuncTorchGradWrapper, PythonTLSSnapshot, FuncTorchDynamicLayerFrontMode, PythonDispatcher].\n\nCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterCPU.cpp:31034 [kernel]\nMeta: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterMeta.cpp:26824 [kernel]\nQuantizedCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterQuantizedCPU.cpp:929 [kernel]\nBackendSelect: registered at C:\\cb\\pytorch_1000000000000\\work\\build\\aten\\src\\ATen\\RegisterBackendSelect.cpp:726 [kernel]\nPython: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:144 [backend fallback]\nFuncTorchDynamicLayerBackMode: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:491 [backend fallback]\nFunctionalize: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\FunctionalizeFallbackKernel.cpp:280 [backend fallback]\nNamed: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\NamedRegistrations.cpp:7 [backend fallback]\nConjugate: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ConjugateFallback.cpp:21 [kernel]\nNegative: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\NegateFallback.cpp:23 [kernel]\nZeroTensor: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\ZeroTensorFallback.cpp:90 [kernel]\nADInplaceOrView: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\VariableFallbackKernel.cpp:63 [backend fallback]\nAutogradOther: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradCPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradCUDA: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradHIP: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradXLA: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradMPS: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradIPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradXPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradHPU: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradVE: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradLazy: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradMeta: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradMTIA: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradPrivateUse1: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradPrivateUse2: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradPrivateUse3: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nAutogradNestedTensor: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\VariableType_2.cpp:17484 [autograd kernel]\nTracer: registered at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\autograd\\generated\\TraceType_2.cpp:16726 [kernel]\nAutocastCPU: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:487 [backend fallback]\nAutocastCUDA: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\autocast_mode.cpp:354 [backend fallback]\nFuncTorchBatched: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\LegacyBatchingRegistrations.cpp:815 [backend fallback]\nFuncTorchVmapMode: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\VmapModeRegistrations.cpp:28 [backend fallback]\nBatched: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\LegacyBatchingRegistrations.cpp:1073 [backend fallback]\nVmapMode: fallthrough registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\VmapModeRegistrations.cpp:33 [backend fallback]\nFuncTorchGradWrapper: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\TensorWrapper.cpp:210 [backend fallback]\nPythonTLSSnapshot: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:152 [backend fallback]\nFuncTorchDynamicLayerFrontMode: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\functorch\\DynamicLayer.cpp:487 [backend fallback]\nPythonDispatcher: registered at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\core\\PythonFallbackKernel.cpp:148 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "model = torch.jit.load(\"Siamese_model(1).pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df885043-ec41-42f5-a6ec-0ead6b47e895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65db0da5-acab-4b01-b557-99b12cd1a5fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f1bd51-eb85-4abd-8425-b3717b954b7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59be1dfb-af25-4233-8973-7f37f58cb5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "3f44a002c00eb28b1b4fca3c5ce30d9006c74d3b23d1eb1c8034a1613b330843"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
